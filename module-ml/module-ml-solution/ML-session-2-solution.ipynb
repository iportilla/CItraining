{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Session-2 Solution: Data Preprocessing and Machine Learning\n",
    "\n",
    "This notebook provides complete solutions for the ML-session-2 exercises.\n",
    "It demonstrates the full machine learning workflow: data preprocessing, feature selection, model training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Sherlock Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df2 = pd.read_csv('sherlock/sherlock_mystery_2apps.csv')\n",
    "print(f\"Dataset shape: {df2.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df2.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "### 3.1 Remove Irrelevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Drop the 'Unnamed: 0' column\n",
    "df2.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(\"Dropped 'Unnamed: 0' column\")\n",
    "print(f\"New shape: {df2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df2.isna().sum())\n",
    "print()\n",
    "\n",
    "# Calculate fraction of missing data in cminflt\n",
    "missing_fraction = df2['cminflt'].isna().sum() / df2['cminflt'].size\n",
    "print(f\"Fraction of missing data in 'cminflt': {missing_fraction:.4f} ({missing_fraction*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Drop rows with missing values\n",
    "df2.dropna(inplace=True)\n",
    "print(f\"After dropping missing values, shape: {df2.shape}\")\n",
    "print(f\"\\nVerify no missing values remain:\")\n",
    "print(df2.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Remove Duplicate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Drop duplicate columns\n",
    "df2.drop(['Mem', 'guest_time', 'queue'], axis=1, inplace=True)\n",
    "print(\"Dropped duplicate columns: Mem, guest_time, queue\")\n",
    "print(f\"\\nRemaining columns:\")\n",
    "print(df2.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Separate Labels from Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate labels and features\n",
    "df2_labels = df2['ApplicationName']\n",
    "df2_features = df2.drop('ApplicationName', axis=1)\n",
    "\n",
    "print(\"Labels:\")\n",
    "print(df2_labels.head())\n",
    "print(f\"\\nLabel value counts:\")\n",
    "print(df2_labels.value_counts())\n",
    "print(f\"\\nFeatures shape: {df2_features.shape}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(df2_features.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Feature Scaling (Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply StandardScaler to normalize features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(df2_features)\n",
    "df2_features_n = pd.DataFrame(scaler.transform(df2_features),\n",
    "                              columns=df2_features.columns,\n",
    "                              index=df2_features.index)\n",
    "\n",
    "print(\"Normalized features (first 10 rows):\")\n",
    "print(df2_features_n.head(10))\n",
    "print(f\"\\nNormalized features statistics:\")\n",
    "print(df2_features_n.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Experiments\n",
    "\n",
    "### 4.1 Experiment 1: Features (CPU_USAGE, vsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for Experiment 1\n",
    "features_exp1 = df2_features_n[['CPU_USAGE', 'vsize']]\n",
    "labels = df2_labels.copy()\n",
    "\n",
    "# Train-test split\n",
    "train_F1, test_F1, train_L1, test_L1 = train_test_split(features_exp1, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Experiment 1: Features (CPU_USAGE, vsize)\")\n",
    "print(f\"Training set: {train_F1.shape}\")\n",
    "print(f\"Test set: {test_F1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "model_lr1 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "%time model_lr1.fit(train_F1, train_L1)\n",
    "\n",
    "# Evaluate\n",
    "test_pred_lr1 = model_lr1.predict(test_F1)\n",
    "acc_lr1 = accuracy_score(test_L1, test_pred_lr1)\n",
    "cm_lr1 = confusion_matrix(test_L1, test_pred_lr1)\n",
    "\n",
    "print(f\"\\nLogistic Regression - Experiment 1\")\n",
    "print(f\"Accuracy: {acc_lr1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm_lr1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree model\n",
    "model_dtc1 = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=8, random_state=42)\n",
    "%time model_dtc1.fit(train_F1, train_L1)\n",
    "\n",
    "# Evaluate\n",
    "test_pred_dtc1 = model_dtc1.predict(test_F1)\n",
    "acc_dtc1 = accuracy_score(test_L1, test_pred_dtc1)\n",
    "cm_dtc1 = confusion_matrix(test_L1, test_pred_dtc1)\n",
    "\n",
    "print(f\"\\nDecision Tree - Experiment 1\")\n",
    "print(f\"Accuracy: {acc_dtc1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm_dtc1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Experiment 2: Features (CPU_USAGE, cutime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Select features for Experiment 2\n",
    "features_exp2 = df2_features_n[['CPU_USAGE', 'cutime']]\n",
    "\n",
    "# Train-test split\n",
    "train_F2, test_F2, train_L2, test_L2 = train_test_split(features_exp2, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Experiment 2: Features (CPU_USAGE, cutime)\")\n",
    "print(f\"Training set: {train_F2.shape}\")\n",
    "print(f\"Test set: {test_F2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Logistic Regression model\n",
    "model_lr2 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "%time model_lr2.fit(train_F2, train_L2)\n",
    "\n",
    "# Evaluate\n",
    "test_pred_lr2 = model_lr2.predict(test_F2)\n",
    "acc_lr2 = accuracy_score(test_L2, test_pred_lr2)\n",
    "cm_lr2 = confusion_matrix(test_L2, test_pred_lr2)\n",
    "\n",
    "print(f\"\\nLogistic Regression - Experiment 2\")\n",
    "print(f\"Accuracy: {acc_lr2:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm_lr2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Decision Tree model\n",
    "model_dtc2 = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=8, random_state=42)\n",
    "%time model_dtc2.fit(train_F2, train_L2)\n",
    "\n",
    "# Evaluate\n",
    "test_pred_dtc2 = model_dtc2.predict(test_F2)\n",
    "acc_dtc2 = accuracy_score(test_L2, test_pred_dtc2)\n",
    "cm_dtc2 = confusion_matrix(test_L2, test_pred_dtc2)\n",
    "\n",
    "print(f\"\\nDecision Tree - Experiment 2\")\n",
    "print(f\"Accuracy: {acc_dtc2:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm_dtc2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Experiment 3: Features (CPU_USAGE, priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Select features for Experiment 3\n",
    "features_exp3 = df2_features_n[['CPU_USAGE', 'priority']]\n",
    "\n",
    "# Train-test split\n",
    "train_F3, test_F3, train_L3, test_L3 = train_test_split(features_exp3, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Experiment 3: Features (CPU_USAGE, priority)\")\n",
    "print(f\"Training set: {train_F3.shape}\")\n",
    "print(f\"Test set: {test_F3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Logistic Regression model\n",
    "model_lr3 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "%time model_lr3.fit(train_F3, train_L3)\n",
    "\n",
    "# Evaluate\n",
    "test_pred_lr3 = model_lr3.predict(test_F3)\n",
    "acc_lr3 = accuracy_score(test_L3, test_pred_lr3)\n",
    "cm_lr3 = confusion_matrix(test_L3, test_pred_lr3)\n",
    "\n",
    "print(f\"\\nLogistic Regression - Experiment 3\")\n",
    "print(f\"Accuracy: {acc_lr3:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm_lr3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Decision Tree model\n",
    "model_dtc3 = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=8, random_state=42)\n",
    "%time model_dtc3.fit(train_F3, train_L3)\n",
    "\n",
    "# Evaluate\n",
    "test_pred_dtc3 = model_dtc3.predict(test_F3)\n",
    "acc_dtc3 = accuracy_score(test_L3, test_pred_dtc3)\n",
    "cm_dtc3 = confusion_matrix(test_L3, test_pred_dtc3)\n",
    "\n",
    "print(f\"\\nDecision Tree - Experiment 3\")\n",
    "print(f\"Accuracy: {acc_dtc3:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm_dtc3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Challenge: Using All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Use all features\n",
    "features_all = df2_features_n.copy()\n",
    "\n",
    "# Train-test split\n",
    "train_F_all, test_F_all, train_L_all, test_L_all = train_test_split(features_all, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Challenge: Using ALL features\")\n",
    "print(f\"Number of features: {features_all.shape[1]}\")\n",
    "print(f\"Features: {features_all.columns.tolist()}\")\n",
    "print(f\"Training set: {train_F_all.shape}\")\n",
    "print(f\"Test set: {test_F_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression with all features\n",
    "model_lr_all = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "%time model_lr_all.fit(train_F_all, train_L_all)\n",
    "\n",
    "# Evaluate\n",
    "test_pred_lr_all = model_lr_all.predict(test_F_all)\n",
    "acc_lr_all = accuracy_score(test_L_all, test_pred_lr_all)\n",
    "cm_lr_all = confusion_matrix(test_L_all, test_pred_lr_all)\n",
    "\n",
    "print(f\"\\nLogistic Regression - All Features\")\n",
    "print(f\"Accuracy: {acc_lr_all:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm_lr_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree with all features\n",
    "model_dtc_all = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=8, random_state=42)\n",
    "%time model_dtc_all.fit(train_F_all, train_L_all)\n",
    "\n",
    "# Evaluate\n",
    "test_pred_dtc_all = model_dtc_all.predict(test_F_all)\n",
    "acc_dtc_all = accuracy_score(test_L_all, test_pred_dtc_all)\n",
    "cm_dtc_all = confusion_matrix(test_L_all, test_pred_dtc_all)\n",
    "\n",
    "print(f\"\\nDecision Tree - All Features\")\n",
    "print(f\"Accuracy: {acc_dtc_all:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm_dtc_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Summary and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table of all results\n",
    "results = {\n",
    "    'Experiment': [\n",
    "        'Exp 1: (CPU_USAGE, vsize)',\n",
    "        'Exp 2: (CPU_USAGE, cutime)',\n",
    "        'Exp 3: (CPU_USAGE, priority)',\n",
    "        'Challenge: All Features'\n",
    "    ],\n",
    "    'LR Accuracy': [acc_lr1, acc_lr2, acc_lr3, acc_lr_all],\n",
    "    'DTC Accuracy': [acc_dtc1, acc_dtc2, acc_dtc3, acc_dtc_all]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY OF ALL EXPERIMENTS\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, results_df['LR Accuracy'], width, label='Logistic Regression', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, results_df['DTC Accuracy'], width, label='Decision Tree', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Model Accuracy Comparison Across Different Feature Sets', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results_df['Experiment'], rotation=15, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Findings and Discussion\n",
    "\n",
    "### Observations:\n",
    "\n",
    "1. **Best Feature Set**: The features (CPU_USAGE, vsize) provide the best accuracy for both models, achieving ~70% accuracy with Logistic Regression and ~72% with Decision Tree.\n",
    "\n",
    "2. **Feature Importance**: Not all features are equally important. The choice of features significantly impacts model performance.\n",
    "\n",
    "3. **All Features Performance**: Using all features does NOT necessarily improve accuracy. This demonstrates the importance of feature selection.\n",
    "\n",
    "4. **Model Comparison**: Decision Tree generally performs slightly better than Logistic Regression on this dataset.\n",
    "\n",
    "### Why Not Use All Features?\n",
    "\n",
    "- **Curse of Dimensionality**: More features can lead to overfitting\n",
    "- **Computational Cost**: More features = longer training time\n",
    "- **Interpretability**: Fewer features are easier to understand and explain\n",
    "- **Noise**: Irrelevant features can introduce noise and reduce model performance\n",
    "- **Data Requirements**: More features require more training data\n",
    "\n",
    "### Cybersecurity Application:\n",
    "\n",
    "This machine learning approach can be used for:\n",
    "- **Malware Detection**: Identify malicious apps based on resource usage patterns\n",
    "- **Anomaly Detection**: Detect unusual application behavior\n",
    "- **Real-time Monitoring**: Classify running applications on mobile devices\n",
    "- **Threat Intelligence**: Build profiles of known malicious applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python3",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
