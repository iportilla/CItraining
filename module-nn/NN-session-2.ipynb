{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**DeapSECURE module 4: Deap Learning**\n",
    "\n",
    "# Session 2: Classifying Smartphone Apps with Keras\n",
    "\n",
    "Welcome to the DeapSECURE online training program!\n",
    "This is a Jupyter notebook for the hands-on learning activities of the\n",
    "[\"Deep Learning\" (DL) module](https://deapsecure.gitlab.io/deapsecure-lesson04-nn/),\n",
    "Episode 5: [\"Classifying Smartphone Apps with Keras\"](https://deapsecure.gitlab.io/deapsecure-lesson04-nn/24-keras-classify/index.html).\n",
    "Please visit the [DeapSECURE](https://deapsecure.gitlab.io/) website to learn more about our training program.\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this session, we will use this notebook to build neural network models to perform a classification task on the Sherlock's \"Applications\" dataset.\n",
    "We will be using a more realistic dataset which contains 18 applications, which will challenge machine learning models.\n",
    "Just like the previous lesson on [machine learning](https://deapsecure.gitlab.io/deapsecure-lesson03-ml/), the goal of this lesson is to build a neural network model which will accurately distinguish these 18 applications based on their resource usage characteristics.\n",
    "We will find out in this session whether the neural network model will surpass the traditional machine learning models in terms of its accuracy.\n",
    "\n",
    "> **Your challenge** in this notebook is to train machine learning models (similar to those introduced in the previous notebooks) using the \"18-apps\" dataset to correctly classify running apps on the smartphone with very high accuracy. Our target is to reach >99% accuracy.\n",
    "\n",
    "\n",
    "**QUICK LINKS**\n",
    "* [Setup](#sec-setup)\n",
    "* [Loading Sherlock Data](#sec-load_data)\n",
    "* [Neural Network Models](#sec-NN)\n",
    "* [Comparison with Traditional Machine Learning Models](#sec-ML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-setup\"></a>\n",
    "## 1. Setup Instructions\n",
    "\n",
    "If you are opening this notebook from the Wahab OnDemand interface, you're all set.\n",
    "\n",
    "If you see this notebook elsewhere, and want to perform the exercises on Wahab cluster, please follow the steps outlined in our setup procedure.\n",
    "\n",
    "1. Make sure you have activated your HPC service.\n",
    "2. Point your web browser to https://ondemand.wahab.hpc.odu.edu/ and sign in with your MIDAS ID and password.\n",
    "3. Create a new Jupyter session with the following parameters: Python version **3.7**, Python suite `tensorflow 2.6 + pytorch 1.10`, Number of Cores **4**, Number of GPU **0**, Partition `main`, and Number of Hours at least **4**. (See <a href=\"https://wiki.hpc.odu.edu/en/ood-jupyter\" target=\"_blank\">ODU HPC wiki</a> for more detailed help.)\n",
    "4. From the JupyterLab launcher, start a new Terminal session. Then issue the following commands to get the necessary files:\n",
    "\n",
    "       mkdir -p ~/CItraining/module-nn\n",
    "       cp -pr /shared/DeapSECURE/module-nn/. ~/CItraining/module-nn\n",
    "\n",
    "Using the file manager on the left sidebar, now change the working directory to `~/CItraining/module-nn`.\n",
    "The file name of this notebook is `NN-session-2.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reminder\n",
    "\n",
    "* Throughout this notebook, `#TODO` is used as a placeholder where you need to fill in with something appropriate. \n",
    "\n",
    "* To run a code in a cell, press `Shift+Enter`.\n",
    "\n",
    "* <a href=\"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\" target=\"_blank\">Pandas cheatsheet</a>\n",
    "\n",
    "* <a href=\"https://deapsecure.gitlab.io/deapsecure-lesson02-bd/10-pandas-intro/index.html#summary-indexing-syntax\" target=\"_blank\">Summary table of the commonly used indexing (subscripting) syntax</a> from our own lesson.\n",
    "\n",
    "* <a href=\"https://keras.io/api/\" target=\"_blank\">Keras API document</a>\n",
    "\n",
    "We recommend you open these on separate tabs or print them;\n",
    "they are handy help for writing your own codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading Python Libraries\n",
    "\n",
    "We need to import the required libraries into this Jupyter Notebook:\n",
    "`pandas`, `numpy`,`matplotlib.pyplot`,`sklearn` and `tensorflow`.\n",
    "Keras is now part of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUSTOMIZATIONS (optional)\n",
    "np.set_printoptions(linewidth=1000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools for machine learning:\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating model performance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# classic machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools for deep learning:\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Import key Keras objects\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-load_data\"></a>\n",
    "## 2. Loading Sherlock Application Dataset\n",
    "\n",
    "First of all, we must repeat the data preparation steps for the \"18-apps\" dataset, including data wrangling and exploration, in this bigger dataset.\n",
    "We will run through typical preprocessing steps below.\n",
    "While executing the codes, please read them and understand what steps were needed to make the data ready for machine learning modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sherlock/sherlock_18apps.csv\", index_col=0)\n",
    "\n",
    "## Summarize the dataset\n",
    "print(\"* shape:\", df.shape)\n",
    "print()\n",
    "print(\"* info::\\n\")\n",
    "df.info()\n",
    "print()\n",
    "print(\"* describe::\\n\")\n",
    "print(df.describe().T)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploring the SherLock \"18-apps\" Dataset\n",
    "\n",
    "Please use the standard pandas functions to explore the new table (e.g. `head()`, `tail()`, and so on).\n",
    "\n",
    "**QUESTION**:\n",
    "\n",
    "1. How many features exist in the original table?\n",
    "2. From the pandas output in the previous cell, do you see any irregularities in the dataset?\n",
    "3. What are the names of the applications contained in this \"18-apps\" dataset?\n",
    "   Do you recognize some of these apps?\n",
    "4. What are the frequencies of these apps in the dataset?\n",
    "   Are there apps that are much represented or underrepresented in the dataset?\n",
    "   According to this data, which apps are used most often by this user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to do your exploration. If needed, add new cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the counts (frequencies) of apps in the ApplicationName column.\n",
    "*Hint*: Use the `value_counts()` method of a pandas' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Find the counts (frequencies) of apps in the ApplicationName column.\"\"\";\n",
    "#app_frequencies = df[#TODO].#TODO\n",
    "#print(app_frequencies)\n",
    "#print('Total num of apps = ', len(app_frequencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Data Cleaning and Preprocessing\n",
    "\n",
    "**EXERCISE**: Based on the irregularities of the data discovered above, please clean the data to make them ready for machine learning modeling.\n",
    "Write the Python codes to clean the data so that we can use this dataset for analysis and machine learning.\n",
    "We will repeat many steps we took for the 2-apps dataset here.\n",
    "\n",
    "> We encourage you to perform data exploration and identify issues with the data before running these cleaning steps.\n",
    "> However, the complete codes for cleaning and preprocessing are given at the end of this notebook to get all of us quicker to the neural network modeling, which is the core mission of this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Enter your data cleaning procedure below\"\"\";\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*HINTS*: Use the following code snippet as the starting point.\n",
    "It is a minimum code skeleton:\n",
    "```python\n",
    "df2 = df.drop(FIXME, axis=1)\n",
    "df2.dropna(FIXME)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **STOP**: Have you done your data cleaning yet? You cannot proceed to the next step with dirty data.\n",
    "> Solution for data cleaning can be found at the very end of this notebook, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data is cleaned, the label column needs to be separated from the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Separate labels from the features\"\"\"\n",
    "#labels = df2#TODO\n",
    "#df_features = df2.drop(#TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding\n",
    "\n",
    "When using neural networks to do a classification task, we need to encode the labels using **one-hot encoding**.\n",
    "This is necessary because many machine learning algorithms require numerically meaningful input and output variables.\n",
    "With one-hot encoding, each 18-apps label is converted into a vector of 18 integers where only one class has a value of 1; all others are zeros.\n",
    "Here is an illustration:\n",
    "\n",
    "| App name                  | One-hot representation                                |\n",
    "|---------------------------|-------------------------------------------------------|\n",
    "| Calendar                  | `1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0`                 |\n",
    "| Chrome                    | `0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0`                 |\n",
    "| ES File Explorer          | `0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0`                 |\n",
    "| ...                       |                                                       |\n",
    "| WhatsApp                  | `0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0`                 |\n",
    "| Zelle                     | `0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1`                 |\n",
    "\n",
    "For more information on why we need one-hot encoding, see these articles:\n",
    "\n",
    "* https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n",
    "* https://machinelearningmastery.com/one-hot-encoding-for-categorical-data/\n",
    "\n",
    "> We did not have to do one-hot in scikit-learn, because the ML objects such as `DecisionTreeClassifier` do it for us behind the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_onehot = pd.get_dummies(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one-hot encoding, there is a `1` in a distinct spot for every category and `0` everywhere else.\n",
    "Below shows the first five rows; notice that there is only a single `1` in each row, with the rest being `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, any input features that are of categorical data type will also have to be encoded using either integer encoding or one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Perform one-hot encoding for **all** categorical features.\"\"\"\n",
    "print(\"Step: Converting all non-numerical features to one-hot encoding.\")\n",
    "# This will be explained later\n",
    "df_features = pd.get_dummies(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: Anything changes after one-hot encoding? Are there changes with the number of columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Inspect the most current dataframe contents:\"\"\";\n",
    "#df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step: Feature scaling using StandardScaler.\"\"\"\n",
    "print(\"Step: Feature scaling with StandardScaler\")\n",
    "\n",
    "# keep the unscaled feature matrix under a different name:\n",
    "df_features_unscaled = df_features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(df_features_unscaled)\n",
    "\n",
    "# Recast the features still in a dataframe form\n",
    "df_features = pd.DataFrame(scaler.transform(df_features_unscaled),\n",
    "                           columns=df_features_unscaled.columns,\n",
    "                           index=df_features_unscaled.index)\n",
    "print(\"After scaling:\")\n",
    "print(df_features.head(10))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step: Perform train-validation split on the master dataset.\n",
    "This should be the last step before constructing & training the model.\n",
    "\"\"\"\n",
    "# percent size reserved for validation dataset\n",
    "val_size = 0.2\n",
    "# if reproducibility is desired:\n",
    "#random_state = 34\n",
    "# for the lesson:\n",
    "random_state = np.random.randint(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step: Train-validation split  val_size=%s  random_state=%s\" \\\n",
    "      % (val_size, random_state))\n",
    "\n",
    "train_features, val_features, train_L_onehot, val_L_onehot = \\\n",
    "    train_test_split(df_features, df_labels_onehot,\n",
    "                     test_size=val_size, random_state=random_state)\n",
    "\n",
    "print(\"- training dataset:   %d records\" % (len(train_features),))\n",
    "print(\"- validation dataset: %d records\" % (len(val_features),))\n",
    "print(\"Now the data is ready for machine learning!\")\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the cell above is executed, you will find new variables defined that hold the training & validation data:\n",
    "\n",
    "* `df_features`: DataFrame of the features for the machine learning models\n",
    "* `labels`: The labels (expected output of the ML models)\n",
    "* `train_features` = training data's features\n",
    "* `val_features` = validation data's features\n",
    "* `train_L_onehot` = training data's labels (one-hot encoded)\n",
    "* `val_L_onehot` = validation data's labels (one-hot encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `random_state` argument above is optional.\n",
    "> It is used to force reproducible results (in this case, reproducible train/validation split), as the train/validation process uses random numbers to shuffle the training data before splitting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Extra step)\n",
    "We need to repeat the same train/test split with non-one-hot labels because it will be needed for comparison with traditional ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_x, val_features_x, train_labels, val_labels = \\\n",
    "    train_test_split(df_features, labels,\n",
    "                     test_size=val_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This is a case where the fixed `random_state` value is important so that we can get identical shuffling for the two `train_test_split` function calls.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Inspecting Preprocessed SherLock \"18-apps\" Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**:\n",
    "Take a peek at the training feature DataFrame *after* the preprocessing steps.\n",
    "What can you learn from this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Take a peek at the training feature DataFrame.\"\"\";\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS:**\n",
    "\n",
    "- How many features for each record?\n",
    "- How many applications in the total dataset?\n",
    "- How many records in the separated training and testing dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-NN\"></a>\n",
    "\n",
    "## 3. Building Neural Networks to Classify Applications\n",
    "\n",
    "Let us now proceed by building some neural network models to classify smartphone apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 First Model: No Hidden Layer\n",
    "\n",
    "The simplest neural network model will have no hidden layer. The following is an example of a neural network model without any hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_Model_no_hidden(learning_rate):\n",
    "    \"\"\"Definition of deep learning model with no hidden layer\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(18, activation='softmax', input_shape=(19,),\n",
    "              kernel_initializer='random_normal')\n",
    "    ])\n",
    "    adam_opt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(optimizer=adam_opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now train this model with an initial *learning rate* of 0.0003 and observe what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = NN_Model_no_hidden(0.0003)\n",
    "model_0_history = model_0.fit(train_features,\n",
    "            train_L_onehot,\n",
    "            epochs=5, batch_size=32,\n",
    "            validation_data=(val_features, val_L_onehot),\n",
    "            verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` function above returns the model's training history as a complex object.\n",
    "Of importance is the `history` attribute, which contains a dictionary of values of loss functions, accuracy, etc. as computed in the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This history can be recast as a DataFrame for easy inspection and/or saved as a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_0_history = pd.DataFrame(model_0_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_0_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_0_history.to_csv('model_0_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualizing Training History\n",
    "\n",
    "Visualization of training history is a helpful aid in understanding the progress of the model training.\n",
    "The model's `fit` function returns an object that contains the history of the loss function, accuracy, and potentially other metrics computed during every epoch of the training.\n",
    "We can use these data to create a few graphs:\n",
    "\n",
    "- A plot of accuracy on the training and validation datasets over training epochs.\n",
    "- A plot of loss on the training and validation datasets over training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(model_history):\n",
    "    # summarize history for loss\n",
    "    plt.plot(model_history.history['loss'])\n",
    "    plt.plot(model_history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(model_history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(model_history.history['accuracy'])\n",
    "    plt.plot(model_history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(model_0_history)\n",
    "plot_acc(model_0_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we will ask the following questions:\n",
    "\n",
    "1. What is the effect of changing the learning rate?\n",
    "   (Examples: 0.03, 0.003, or 0.00003)\n",
    "   \n",
    "2. What will happen if we increase the `epochs` value? (To 10, 20?)\n",
    "\n",
    "3. What is the ultimate accuracy of a no-hidden-layer model compared to Decision Tree and Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**:\n",
    "\n",
    "* Does this training result look converged to you? (The training has converged to a solution if the changes of the loss function and accuracy between two consecutive epochs have dropped to a very small value--for example, the values have changed by 0.1% or less between the two epochs.)\n",
    "\n",
    "* If this training does not look converged, what can you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 One Hidden Layer\n",
    "\n",
    "Apparently, the first NN model that we created above did not perform very well.\n",
    "One way to improve the performance of a NN model is to add one or more hidden layers.\n",
    "The function below has a hidden layer, an output layer, and utilizes the `Adam` optimizer that was used in the previous notebook.\n",
    "We will use this function to test the performance based on different parameters (number of hidden neurons, hidden layers, learning rate, etc.).\n",
    "To start, let us try an example of a model with 1 hidden layer, `18` hidden neurons, and a learning rate of `0.0003`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_Model_1H(hidden_neurons, learning_rate):\n",
    "    \"\"\"Definition of deep learning model with one dense hidden layer\"\"\"\n",
    "    model = Sequential([\n",
    "        # More hidden layers can be added here\n",
    "        Dense(hidden_neurons, activation='relu', input_shape=(19,),\n",
    "              kernel_initializer='random_normal'), # Hidden Layer\n",
    "        Dense(18, activation='softmax',\n",
    "              kernel_initializer='random_normal')  # Output Layer\n",
    "    ])\n",
    "    adam_opt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(optimizer=adam_opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = NN_Model_1H(18,0.0003)\n",
    "model_1_history = model_1.fit(train_features,\n",
    "                              train_L_onehot,\n",
    "                              epochs=10, batch_size=32,\n",
    "                              validation_data=(val_features, val_L_onehot),\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(model_1_history)\n",
    "plot_acc(model_1_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Activities: Prelude to Model Tuning (Self-Exploration)\n",
    "\n",
    "Now that we know how to use the function `NN_model_1H`, we are ready to run a variety of tests using different hyperparameters.\n",
    "This will be a topic for the subsequent notebook.\n",
    "But those who are curious can get ahead by training similar models which differ in the number of hidden neurons.\n",
    "\n",
    "  - What happens to the model's accuracy if we *increase* the number of hidden neurons (e.g. **25, 36, 40, 80** or beyond)?\n",
    "  - What happens to the model's accuracy if we *decrease* the number of hidden neurons (e.g. **12, 8, 4, 2, 1**)?\n",
    "\n",
    "We will run these tests in the next notebook, where we perform *model tuning* to find the optimal network architecture to perform the 18-apps classification task.\n",
    "\n",
    "> **HINT:**\n",
    "> The easiest way to do this exploration is to simply copy the code in the cell above and paste it in a new cell below, since most of the hyperparameters (`hidden_neurons`, `learning_rate`, `batch_size`, etc.) can be changed when calling the function or when fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Start self exploration here\"\"\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "\n",
    "This process of experimentation with different parameters for the neural network can get repetitive and cause this notebook to become very long.\n",
    "Instead, it would be more beneficial to run experiments like this in a scripting environment.\n",
    "To do this, we need to identify the relevant code elements for our script.\n",
    "In a general sense, this is what we should pick out:\n",
    "\n",
    "* Useful Python libraries & user-defined functions\n",
    "* Proper sequence of commands that were run throughout this notebook (i.e. one-hot encoding must be done before training the models)\n",
    "* Code cells that require repetition to run many tests (i.e. the cells right above this section)\n",
    "\n",
    "In brief, once the initial experiments are done and we have established a working pipeline for machine learning, we need to change the way we work.\n",
    "Real machine-learning work requires many repetitive experiments, each of which may take a long time to complete.\n",
    "Instead of running many experiments in Jupyter notebooks, where each will require us to wait for a while to finish, we need to be able to carry out many experiments in parallel so that we can obtain our results in a timely manner.\n",
    "This is key reason why we should make a script for these experiments and submit the script to run them in batch (non-interactive model).\n",
    "HPC is well suited for this type of workflow--in fact it is most efficient when used in this way.\n",
    "Here are the key components of the \"batch\" way of working:\n",
    "\n",
    "* A job scheduler (such as SLURM job scheduler on HPC) to manage our jobs and run them on the appropriate resources;\n",
    "* The machine learning script written in Python, which will read inputs from files and write outputs to files and/or standard output;\n",
    "* The job script to launch the machine learning script in the non-interactive environment (e.g. HPC compute node);\n",
    "* A way to systematically repeat the experiments with some variations. This can be done by adding some command-line arguments for the (hyper)parameters that will be varied for each test.\n",
    "\n",
    "In your hands-on package, there is a folder called `expts-sherlock` which contains a sample Python script and SLURM job script that you can submit to the HPC cluster:\n",
    "\n",
    "* `NN_Model-064n.py` shows an example of how a script converted from this notebook would look like.\n",
    "  We recommend only one experiment per script to avoid complication.\n",
    "\n",
    "* `NN_Model-064n.wahab.job` is the corresponding job script for ODU's Wahab cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"sec-ML\"></a>\n",
    "## 4. Comparison with Traditional Machine Learning \n",
    "\n",
    "Now, we first try the traditional machine learning algorithms learned in the previous session. \n",
    "Here we test on **Decision Tree** and **Logistic Regression**. \n",
    "To simplify the code, we will use the `model_evaluate` function to evaluate the performance of a machine learning model (whether traditional ML or neural network model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model,test_F,test_L):\n",
    "    test_L_pred = model.predict(test_F)\n",
    "    print(\"Evaluation by using model:\",type(model).__name__)\n",
    "    print(\"accuracy_score:\",accuracy_score(test_L, test_L_pred))\n",
    "    # Uncomment the following line to show the confusion matrix:\n",
    "    #print(\"confusion_matrix:\",\"\\n\",confusion_matrix(test_L, test_L_pred))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**: You can uncomment the print statement above if you'd like to examine the confusion matrix whenever you evaluate the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the old-fashioned train labels as texts below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_dtc = DecisionTreeClassifier(criterion='entropy',\n",
    "                                   max_depth=6,\n",
    "                                   min_samples_split=8)\n",
    "%time ML_dtc.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_evaluate(ML_dtc, val_features, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_log = LogisticRegression(solver='lbfgs')\n",
    "%time ML_log.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate(ML_log, val_features, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTIONS**:\n",
    "\n",
    "* Do you notice issues with the training process of any of the models above?\n",
    "* (Optional) Can you find a way to ensure full convergence of the training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we have a pretty good background knowledge about this dataset.\n",
    "And we know the accuracy scores we can get by using the Decision Tree and Logistic Regression methods,\n",
    "which are reasonably good, but not close to 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing the Computation\n",
    "\n",
    "Do you notice that the training of logistic regression model takes a while?\n",
    "Often we want to know *how long* this actually takes place.\n",
    "We can get this timing easily in Jupyter by prepending `%time` to the Python statement we'd like to measure the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### About the Warning Message\n",
    ">\n",
    "> The training phase stops with an error:\n",
    ">\n",
    "> ```\n",
    "> ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "> STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "> ```\n",
    ">\n",
    "> This happens because the solver fails to reach convergence after the maximum number of iteration (default=100) is reached.\n",
    "> You may want to investigate by trying different solvers in the `LogisticRegression` object.\n",
    "> Try the Scikit-learn documentation on [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), the `solver` argument, if you are interested.\n",
    "> That may confirm whether a reasonable solution has indeed been reached (i.e. different solvers yield about the same accuracy). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Data Cleaning (Sec. 2.2)\n",
    "\n",
    "The absolute bare minimum cleaning steps for the Sherlock \"18-apps\" data would be like this:\n",
    "\n",
    "```python\n",
    "df2 = df.drop(['cminflt', 'guest_time'], axis=1)\n",
    "df2.dropna(inplace=True)\n",
    "```\n",
    "\n",
    "### Alternative Solution (Advanced Users)\n",
    "\n",
    "Verbose code is often helpful especially when automating the machine learning workflow.\n",
    "The following segments of code are examples of self-documenting code which prints clear messages as it processes the data.\n",
    "\n",
    "**STEP 1**: Columns with obviously irrelevant and missing data are removed.\n",
    "```python\n",
    "# Missing data or bad data\n",
    "del_features_bad = [\n",
    "    'cminflt', # all-missing feature\n",
    "    'guest_time', # all-flat feature\n",
    "]\n",
    "df2 = df.drop(del_features_bad, axis=1)\n",
    "\n",
    "print(\"Cleaning:\")\n",
    "print(\"- dropped %d columns: %s\" % (len(del_features_bad), del_features_bad))\n",
    "```\n",
    "Output:\n",
    "```\n",
    "Cleaning:\n",
    "- dropped 2 columns: ['cminflt', 'guest_time']\n",
    "```\n",
    "\n",
    "**STEP 2**: Remove rows with missing data.\n",
    "```python\n",
    "print(\"- remaining missing data (per feature):\")\n",
    "\n",
    "isna_counts = df2.isna().sum()\n",
    "print(isna_counts[isna_counts > 0])\n",
    "print(\"- dropping the rest of missing data\")\n",
    "\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "print(\"- remaining shape: %s\" % (df2.shape,))\n",
    "```\n",
    "Output:\n",
    "```\n",
    "- remaining missing data (per feature):\n",
    "CPU_USAGE      52\n",
    "cutime         52\n",
    "num_threads    52\n",
    "priority       52\n",
    "rss            52\n",
    "state          52\n",
    "stime          52\n",
    "utime          52\n",
    "vsize          52\n",
    "dtype: int64\n",
    "- dropping the rest of missing data\n",
    "- remaining shape: (273077, 17)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
