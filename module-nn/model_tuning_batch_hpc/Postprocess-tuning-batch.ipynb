{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16334cf7-ba3e-4505-bb92-99f032b2d986",
   "metadata": {},
   "source": [
    "# Post-Processing Model Tuning Experiments\n",
    "\n",
    "This Jupyter notebook contains hands-on learning activities for the DeapSECURE's \"[Deep Learning (Neural Networks)](https://deapsecure.gitlab.io/deapsecure-lesson04-nn/)\" module, Episode 7: \"[Effective Deep Learning Workflow on HPC](https://deapsecure.gitlab.io/deapsecure-lesson04-nn/31-batch-tuning-hpc/index.html)\". Please visit the [DeapSECURE website](https://deapsecure.gitlab.io/) to learn more about our training program.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "After we ran all the model tuning experiments on HPC, now it is time to start recapping the results, and later analyze the findings.\n",
    "Each hyperparameter set in these experiments correspond to a single model training run, and the outputs are stored in a separate folder that has been systematically named.\n",
    "\n",
    "The final objective of the postprocessing stage is to gather all the results from these individual model trainings to create intermediate tables that will be further analyzed in the next stage (\"post-analysis\").\n",
    "\n",
    "However, prior to doing this, we must validate the model training runs that were submitted in batch mode.\n",
    "At the end of these runs, the training histories were stored in `model_history.csv` files.\n",
    "We must inspect at the progress of the training did not show anything anomalous, such as lack of convergence, overfitting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da88d7-7f85-49e6-900b-e15852bf3a25",
   "metadata": {},
   "source": [
    "## Import modules and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdb3ce-178e-4655-ac76-becfaadc55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b5d40-8efa-46cb-9cda-7b985f99d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sherlock_ML_toolbox import fn_out_history_1H, fn_out_history_XH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb0d34a-81d2-44f6-802b-1d3a8fa75dc8",
   "metadata": {},
   "source": [
    "The `plot_training_history` function creates a two-panel plot to visually inspect the training history in terms of the loss (left panel) and accuracy (right panel).\n",
    "This will aid identification of abnormal training outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68262b9-2521-4671-9680-5729f334d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history_file, subtitle):\n",
    "    \"\"\"\n",
    "    Creates and displays a two-panel subplots to visualize the progress\n",
    "    of a model training run.\n",
    "    The left panel contains the training and validation loss vs. epochs;\n",
    "    the right panel contains the training validation accuracy vs. epochs.\n",
    "    This function expects to read the training history from a CSV file,\n",
    "    which contains loss & accuracy values computed with training and validation\n",
    "    sets.\n",
    "    \n",
    "    Args:\n",
    "      history_file (str): The pathname of the CSV file.\n",
    "      subtitle (str): A string to append to the plot's titles.\n",
    "    \"\"\"\n",
    "    # Initialize the subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "    \n",
    "    # The history file contains the data to plot\n",
    "    epochMetrics = pd.read_csv(history_file)\n",
    "    # The epoch values corresponds to the index of the read dataframe,\n",
    "    # which will be 0, 1, 2, ...\n",
    "    epochs = np.array(epochMetrics.index)\n",
    "\n",
    "    # Plot the loss subplot\n",
    "    axs[0].plot(epochs, epochMetrics['loss'])\n",
    "    axs[0].plot(epochs+1, epochMetrics['val_loss'])\n",
    "\n",
    "    # Code to add the title, axis labels, etc.\n",
    "    axs[0].set_title(\"Model Loss: \" + subtitle)\n",
    "    axs[0].legend([\"Train Loss\", \"Val Loss\"])\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].set_xlabel(\"Epochs\")\n",
    "    axs[0].set_xlim(xmin=0)\n",
    "    axs[0].set_ylim(ymin=0)\n",
    "\n",
    "    # Plot the accuracy subplot\n",
    "    axs[1].plot(epochs, epochMetrics['accuracy'])\n",
    "    axs[1].plot(epochs+1, epochMetrics['val_accuracy'])\n",
    "\n",
    "    # Code to add the title, axis labels, etc.\n",
    "    axs[1].set_title(\"Model Accuracy: \" + subtitle)\n",
    "    axs[1].legend([\"Train Accuracy\", \"Val Accuracy\"])\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    axs[1].set_xlabel(\"Epochs\")\n",
    "    axs[1].set_xlim(xmin=0)\n",
    "\n",
    "    # create space between the plots\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, \\\n",
    "                        wspace=0.4, hspace=0.4) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c374c6-ca8a-4783-ac41-eab198b62eb4",
   "metadata": {},
   "source": [
    "## Hidden Neurons Experiment\n",
    "\n",
    "In this experiment, we trained many classifier models which have varied values of `hidden_neurons`, the number of neurons in the (only) hidden layer of the model.\n",
    "Our goal is to observe the effect of `hidden_neurons` hyperparameter on the accuracy of the model.\n",
    "The model training results are stored in subfolders (one folder per model training) under the `scan-hidden-neurons` folder.\n",
    "\n",
    "Once the experimental results are collected, this postprocessing stage gathers all these results, validates them, and creates the intermediate data for final analysis.\n",
    "This stage consists of the following steps:\n",
    "\n",
    "1. First, scan all the results within the `scan-hidden-neurons` folder.\n",
    "\n",
    "2. Validate the model-training runs, to ensure that they show normal behavior.\n",
    "   (For example, we want to watch out for non-convergence, overfitting, or other anomalies.)\n",
    "\n",
    "3. Extract the final metrics (loss & accuracy) from the trained models from the last epoch, create a dataframe to combine these metrics from multiple runs, and save this into an intermediate CSV table.\n",
    "\n",
    "In the post-analysis stage (the next one) we will obtain the insight on how these metrics change as a result of the hyperparameter variations.\n",
    "From this stage, we will determine the optimal set of hyperparameters for the `sherlock_18apps` classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d66d321-098a-40bb-9a7f-7dd39ac49ebc",
   "metadata": {},
   "source": [
    "### Step 1: Discover and Load the Results\n",
    "\n",
    "Let's inspect the content of one history file and determine the steps needed to get the values that we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c257fc-6662-421e-aba9-bc8eb380b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect what the last epochMetrics looks like (from the \"baseline model run\")\n",
    "epochMetrics = pd.read_csv(\"scan-hidden-neurons/model_1H18N_lr0.0003_bs32_e30/model_history.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610ed461-a1d7-440d-ba3d-c26e0efc0c3f",
   "metadata": {},
   "source": [
    "**EXERCISE**: Examine the `epochMetrics` data structure and the contents (at least the \"head\" and the \"tail\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976727f9-efa4-4eb9-982c-65da7aadf421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#epochMetrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ed2f7-2ad7-40aa-83ab-0b0dd51f5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochMetrix.#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aedeaa8-ee83-4bd8-a0f1-ac3654cf46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFO\n",
    "epochMetrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d63c5-9fea-4418-879b-58ebe0531eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFO\n",
    "epochMetrics.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2777b95-72c3-4b57-a0ed-0db9d58b184a",
   "metadata": {},
   "source": [
    "The `plot_training_history` function will be used to visualize the progress of the training (the loss and accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12d610-f724-47be-817b-11928674ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(\"scan-hidden-neurons/model_1H18N_lr0.0003_bs32_e30/model_history.csv\",\n",
    "                      subtitle=\"1H18N baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731fc23-c38b-4e91-85f3-e44f282ee553",
   "metadata": {},
   "source": [
    "**EXERCISE**: These plots show the behavior of the loss and accuracy in a normal training run.\n",
    "Please study the behavior of these metrics above as a function of the number of epochs, and write a few descriptive sentences regarding what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5041435-3ae5-4fa3-bd75-7ade24894351",
   "metadata": {},
   "source": [
    "> **ANSWER**: #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec422855-69d2-4248-8deb-ccfe8e365616",
   "metadata": {},
   "source": [
    "**QUESTION**: How to fetch the last row of this dataframe (labeled **29** above)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d93a6-6bb1-4919-9d40-c6763b0f5c6b",
   "metadata": {},
   "source": [
    "> **ANSWER**: #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec3ed0-2c5e-47bd-9d1a-74d6d191ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fetch the last row of this dataframe, which is row labeled **29**\"\"\";\n",
    "\n",
    "#epochMetrics.#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434f587-b9e2-4aa8-873a-a83ffe6db0de",
   "metadata": {},
   "source": [
    "Try convert the row data into a dict, because we will add one more column later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1ecbe-3411-4744-bcfa-e11d0c0d1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochMetrics.iloc[29,:].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646aa9d-6aa6-4718-a6b5-6f5038ec0d45",
   "metadata": {},
   "source": [
    "#### Systematic File Naming\n",
    "\n",
    "Because the filenames are designed to be systematic, it is best to encode the filename construction as a function.\n",
    "The function arguments would be the hyperparameters (num of hidden neurons, learning rate, batch size), as well as num of epochs. In addition, a subdirectory prefix is provide because we store our runs in separate directory tree per experiment.\n",
    "The `sherlock_ML_toolbox` module has a function named `fn_out_history_1H` to get the history file for a particular run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a2a510-e216-4138-82fd-06f161bb5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the history filename function\n",
    "fn_out_history_1H('scan-hidden-neurons', 18, 0.003, 32, 30) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8167cd5b-8e08-40b6-b580-fbfdf4849484",
   "metadata": {},
   "source": [
    "#### Result Discovery\n",
    "\n",
    "Given the folder name pattern above, we can discover which runs have been accomplished in our own model tuning folders.\n",
    "We can use `ls` and shell wildcard to find this out (the `-d` flag prevents `ls` from listing the contents of the directories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c4c8f-4aaf-4e4f-a4f4-95d2ecec1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l -d scan-hidden-neurons/model_1H*N_lr*_bs*_e*/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9f443-7656-42a1-b2b4-eaefd7bda77b",
   "metadata": {},
   "source": [
    "Based on our run, we varied the value of `hidden_neurons` in this experiment, which can be found in the batch job submission script.\n",
    "(Remember the contents of the `submit-scan-hidden-neurons.sh` script?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b84d4-0b58-4cc2-a0fc-05b9dd010060",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat scan-hidden-neurons/submit-scan-hidden-neurons.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c46d8-d91e-46ee-b6df-66b91676b657",
   "metadata": {},
   "source": [
    "(You may have more values of `hidden_neurons` that you tried; please look at your own runs.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204c703-e7c2-4bfd-9d53-6f31b7cbad5a",
   "metadata": {},
   "source": [
    "**EXERCISE** - Now create a list named `listHN` which contains the values of `hidden_neurons` used in your training runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604547b-c541-4a82-88a9-7a1dc4180303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Enter the numbers of hidden neurons that you tried in your experiment,\n",
    "see the listing of the `submit-scan-hidden-neurons.sh` script above.\"\"\";\n",
    "\n",
    "#listHN = [ #TODO ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107833e-8483-4971-aa8b-87cc42a3de1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base folder of the experiment\n",
    "dirPathHN = \"scan-hidden-neurons\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999f1c1-5be1-45c1-b86c-3cdc7ddda24e",
   "metadata": {},
   "source": [
    "### Step 2: Validation of Model Training: Visual Inspection\n",
    "\n",
    "The validation step is easiest done by graphically inspecting the training histories using the `plot_training_history` function.\n",
    "We can do this for all the runs with the different numbers of hidden neurons by invoking a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a558fc3-b567-4c55-b72f-770524ade6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, HN in enumerate(listHN):\n",
    "    plot_training_history(fn_out_history_1H(dirPathHN, HN, 0.0003, 32, 30),\n",
    "                          subtitle=\"1H\"+str(HN)+\"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25d465-9a74-4209-b15c-ab30368f1f93",
   "metadata": {},
   "source": [
    "**QUESTIONS**: Based on the plots shown above, inspect whether the training runs went as expected.\n",
    "\n",
    "1) Visually inspect for any anomalies. In the answer box below, mark the runs that produce \"abonrmal training trends\", i.e. where the \"loss vs epochs\" and/or \"accuracy vs epochs\" curves exhibit a different behavior from what shown in the earlier 2-panel plot.\n",
    "\n",
    "2) Visually (or numerically) check for convergence (e.g. check the loss or accuracy for the last 4-5 epochs; what their slopes look like in this region; any fluctuations?)\n",
    "\n",
    "3) Observe the differences in the *final* accuracies as a result of different `hidden_neurons` values. (We will do this more carefully in the next phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f9b31-3d2d-451a-b391-472fce3770e4",
   "metadata": {},
   "source": [
    "> #### **ANSWERS**\n",
    ">\n",
    "> 1. Runs with `hidden_neurons` = #TODO... have odd-looking trend. Their curves look like #TODO ... (describe what you see)\n",
    ">\n",
    "> 2. #TODO\n",
    ">\n",
    "> 3. #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f744e8-97ef-43c8-8825-8f71342cb212",
   "metadata": {},
   "source": [
    "This is the step where one can easily look at the graphics and determine which hyperparameter regime yield good results, and which regime should be avoided because they produce bad results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3bc27-2ec3-4d83-8c21-7c3221294cec",
   "metadata": {},
   "source": [
    "### Step 3: Create a Result DataFrame for `hidden_neurons` Hyperparameter Scan\n",
    "\n",
    "After validation and everything else,\n",
    "what we want to analyze will be the changes of the final metrics\n",
    "as the input hyperparameter is varied (in this case, `hidden_neurons`).\n",
    "We will do this in the next notebook,\n",
    "but for now, we will collect these final metrics\n",
    "with the relevant hyperparameter(s) and metadata\n",
    "into an intermediate dataframe and save them as a CSV file.\n",
    "\n",
    "In the batch runs, we ran every model training with 30 epochs.\n",
    "Based on the the validation above,\n",
    "it is sufficient for now to collect the metrics at epoch=30\n",
    "as the final metrics for each `hidden_neurons` hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f97582-03e1-45d7-9781-f7dda9a56588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the epoch number from which we want to extract results\n",
    "# for analysis of hyperparameter effects\n",
    "# (corresponding to epoch #30)\n",
    "lastEpochNum = 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b5b2f-acb2-4f99-a38a-e6073ebea914",
   "metadata": {},
   "source": [
    "Now we scan the results from the training runs in \n",
    "\n",
    "We use a loop to read all the output files from this experiment\n",
    "and gather the final metrics into a new dataframe called `df_HN`\n",
    "(where `HN` is, again, a shorthand for \"hidden neurons tuning experiment\").\n",
    "The sequence of the varied hyperparameter specified in `listHN`,\n",
    "defined aboves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c598ff0c-fa10-4edc-bbd8-3b9ffe99a4da",
   "metadata": {},
   "source": [
    "#### *Method 1: Via a temporary data structure*\n",
    " \n",
    "In this method, we will construct and fill a temporary data structure (`all_lastEpochMetrics`) dynamically before forming the dataframe.\n",
    "This approach is useful when the size of the data (e.g. total number of rows) is not known *a priori*.\n",
    "\n",
    "The following is a *simplified* loop which shows the logic\n",
    "of this intermediate data construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f7ce3-6c19-4889-a84d-33dfe9c2ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lastEpochMetrics = []\n",
    "# Fill in the rows for the DataFrame\n",
    "for HN in listHN:\n",
    "    # Read the history CSV file and get the last row's data,\n",
    "    # which corresponds to the last epoch data.\n",
    "    #run_subdir = \"model_1H\" + str(HN) + \"N_lr0.0003_bs32_e30\"\n",
    "    #result_csv = os.path.join(dirPathHN, run_subdir, \"model_history.csv\")\n",
    "    result_csv = fn_out_history_1H(dirPathHN, HN, 0.0003, 32, 30)\n",
    "    print(\"Reading:\", result_csv)\n",
    "    epochMetrics = pd.read_csv(result_csv)\n",
    "    # Fetch the loss, accuracy, val_loss, and val_accuracy from the last epoch\n",
    "    # (should be the last row in the CSV file unless there's something wrong\n",
    "    # during the traning)\n",
    "    lastEpochMetrics = epochMetrics.iloc[lastEpochNum, :].to_dict()\n",
    "    # Attach the \"neurons\" value\n",
    "    lastEpochMetrics[\"hidden_neurons\"] = HN\n",
    "    all_lastEpochMetrics.append(lastEpochMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae88003-e886-47d2-8b92-8f342cf8d03c",
   "metadata": {},
   "source": [
    "> In real-world cases, model training may employ \"early stopping\"\n",
    "> criteria which may lead to different numbers of epochs\n",
    "> for different training runs.\n",
    "> In this case, you will have to modify the output reading algorithm\n",
    "> to find the correct final epoch for each training run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1fdba-091b-4c63-b34f-4aafc5f7774e",
   "metadata": {},
   "source": [
    "**EXERCISE**:\n",
    "Look over the contents of `all_lastEpochMetrics` and verify if the data has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1de78-f052-49e9-99e8-9c1ec95bb720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare against one result\n",
    "\n",
    "! tail -n 1 scan-hidden-neurons/model_1H1024N_lr0.0003_bs32_e30/model_history.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca81a76-e2f7-446a-9fee-297ff769e679",
   "metadata": {},
   "source": [
    "Now construct the `df_HN` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc962e0-9c44-455c-aa16-a37979a66c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HN = pd.DataFrame(all_lastEpochMetrics, \n",
    "                     columns=[\"hidden_neurons\", \"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59145705-7b8c-4b42-826c-8cb8c58eeab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_HN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6964d-ed99-42f5-8760-3678bb0b9bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just check the data structure is according to what we expect\n",
    "df_HN.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e0dfed-b0c5-4a63-b452-878467d26c0e",
   "metadata": {},
   "source": [
    "### Step 4: Save the Intermediate DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7daa808-eda5-4398-bb1f-9373f6d75f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HN.to_csv(\"post_processing_hpc_neurons.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9517d-ac71-40e8-82b1-c1842dbc383a",
   "metadata": {},
   "source": [
    "This intermediate dataframe is good for further analysis.\n",
    "We will analyze the data on a subsequent notebook.\n",
    "\n",
    "Now let us postprocess the other experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1133d-cbfa-4af2-a3cd-ca10d0b66bb2",
   "metadata": {},
   "source": [
    "### *OPTIONAL: Generalized metrics loader:* `load_bulk_final_metrics`\n",
    "\n",
    "The method above is fine to use *ad hoc*;\n",
    "however, the resulting intermediate data lacks additional information.\n",
    "Only `hidden_neurons` is stored with the dataframe,\n",
    "whereas other hyperparameters (e.g. learning rate, ...) are not kept.\n",
    "In batch computation, we want to keep track of which calculations (or experiments) produces which results.\n",
    "All of these information bits need to be somehow preserved\n",
    "when constructing an intermediate dataset for further analysis.\n",
    "Otherwise, the contexts that are lost may not be recoverable later on;\n",
    "consequently we could not trace back the origin of our results.\n",
    "In scientific research, the lost context will compromise the *reproducibility*\n",
    "of the experiment.\n",
    "\n",
    "In this lesson, we choose to store these contexts together with the dataframe.\n",
    "We will to store the following bits of information:\n",
    "\n",
    "* All the hyperparameters used (whether varied or fixed in this experiment)\n",
    "* \"Experiment code\", a short descriptive string that can quickly identify the type of experiment\n",
    "* Batch job ID.\n",
    "\n",
    "In this simplified analysis, we will omit batch job ID (`Job_ID`) below but prepare a column in the dataframe for your own exercise to fill.\n",
    "This field is meant to store the job ID number assigned by SLURM, so that we can associate the result to the specific computation and outputs.\n",
    "This is important to troubleshoot issues/errors\n",
    "when our experiments grow big\n",
    "(e.g. we scan very many hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d00e18-4b69-49d5-a725-c4b53c2bea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bulk_final_metrics(expt_name, hyperparams_list, expt_code):\n",
    "    \"\"\"Load final metrics (final training outcomes) in bulk.\n",
    "    For this lesson, \"training outcomes\" are defined as the metrics computed\n",
    "    in the last epoch of the training.\n",
    "    \n",
    "    Args:\n",
    "      expt_name (str): Base directory, whose name also should describe the experiment.\n",
    "      hyperparams_list (list): A list of hyperparameter sets.\n",
    "        Each hyperparameter set is defined as a 4-tuple of\n",
    "        (hidden_neurons, learning_rate, batch_size, epochs)\n",
    "        used to train a model.\n",
    "      expt_code (str): A short string suffix to describe the experiment\n",
    "        in the dataframe.\n",
    "    \"\"\"\n",
    "    all_lastEpochMetrics = []\n",
    "    Expt_IDs = []\n",
    "    # Fill in the rows for the DataFrame\n",
    "    for (HN, LR, BS, EPOCH) in hyperparams_list:\n",
    "        # Read the history CSV file and get the last row's data,\n",
    "        # which corresponds to the last epoch data.\n",
    "        result_csv = fn_out_history_1H(expt_name, HN, LR, BS, EPOCH)\n",
    "        print(\"Reading:\", result_csv, flush=True)\n",
    "\n",
    "        # Define which epoch we want to extract the metrics from:\n",
    "        lastEpochNum = EPOCH-1\n",
    "        epochMetrics = pd.read_csv(result_csv)\n",
    "        # Fetch the loss, accuracy, val_loss, and val_accuracy from the last epoch\n",
    "        # (should be the last row in the CSV file unless there's something wrong\n",
    "        # during the traning)\n",
    "        lastEpochMetrics = epochMetrics.iloc[lastEpochNum, :].to_dict()\n",
    "        # Attach the \"metadata\" values (Model_Type, Job_ID, hyperparameters)\n",
    "        lastEpochMetrics[\"hidden_neurons\"] = HN\n",
    "        lastEpochMetrics[\"learning_rate\"] = LR\n",
    "        lastEpochMetrics[\"batch_size\"] = BS\n",
    "        lastEpochMetrics[\"epoch\"] = lastEpochNum\n",
    "        lastEpochMetrics[\"Expt_ID\"] = None  # Will fill this later\n",
    "        lastEpochMetrics[\"Job_ID\"] = None  # FIXME for advanced learners\n",
    "        all_lastEpochMetrics.append(lastEpochMetrics)\n",
    "        # Ad-hoc: Expt_IDs is a string column and has to be added separately below!\n",
    "        # For some reason, initializing it with the rest of the columns\n",
    "        # doesn't work because of a non-numerical datatype\n",
    "        Expt_IDs.append(f\"1H{HN}N{expt_code}\")\n",
    "\n",
    "    #print(all_lastEpochMetrics[:3])  # only for debugging\n",
    "    # Construct the dataframe\n",
    "    cols_outcomes = [\n",
    "        \"Expt_ID\", \"Job_ID\", \n",
    "        \"hidden_neurons\", \"learning_rate\", \"batch_size\", \"epoch\",\n",
    "        \"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"\n",
    "    ]\n",
    "    df_outcomes = pd.DataFrame(all_lastEpochMetrics, columns=cols_outcomes)\n",
    "    # Attach the Model_Type here; it will automatically switch the dtype to the correct one\n",
    "    # to support string:\n",
    "    df_outcomes[\"Expt_ID\"] = Expt_IDs\n",
    "    return df_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc7192-cdaa-4038-835f-0a7cd5e68ef8",
   "metadata": {},
   "source": [
    "The generalized final-metrics loader above relies on a list of hyperparameter sets to decide which run results to load.\n",
    "Here is the way to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16b02d-46dd-4825-856e-0bcac15cc58f",
   "metadata": {},
   "source": [
    "Now create an \"extended\" `df_HN` which has the complete hyperparameters & other metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c6420-7c9c-47cc-84f8-619a50beb112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HN_ext = load_bulk_final_metrics(\"scan-hidden-neurons\",\n",
    "                                    hyperparams_HN,\n",
    "                                    \"-neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b905dd-b895-462e-a42d-1fca6a712061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HN_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f3834-8507-4bdc-9af8-77123e658ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HN_ext.to_csv(\"post_processing_hpc_neurons_ext.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac809f-a16b-4615-9ccd-0c4d391336ec",
   "metadata": {},
   "source": [
    "## Learning Rate Experiment\n",
    "\n",
    "Now that we have laid a good foundation with the \"scan-hidden-neuron\" experiment,\n",
    "we will reapply the postprocessing to the \"learning rate\" experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d061a-aedc-49bc-83b2-75e8e27f73b2",
   "metadata": {},
   "source": [
    "### Step 1: Discover and Load the Results (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc2ed2-c94e-45c9-a34a-e950e9fc9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l -d scan-learning-rate/model_1H*N_lr*_bs*_e*/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71cf09-a843-4a82-b8aa-908f025c380e",
   "metadata": {},
   "source": [
    " **EXERCISE** - Now create a list named `listLR` which contains the values of `learning_rate`'s used in your training runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99272c80-ee16-478a-9d78-aa11a42b488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Enter the learning rates that you tried in your experiment,\n",
    "see the contents of the `submit-scan-learning-rate.sh` script in your working directory.\"\"\";\n",
    "\n",
    "#dirPathLR = #TODO\n",
    "#listLR = [ #TODO ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac48d01-dbb6-4e6c-b719-c713d5aebc4b",
   "metadata": {},
   "source": [
    "### Step 2: Validation of Model Training: Visual Inspection (LR)\n",
    "\n",
    "Let's repeat the visual validation of model training runs for the scan over learning rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db729df6-bf16-467b-ae51-3dd0dbada343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Repeat the validation of model training, but now for the learning rate experiment\"\"\";\n",
    "\n",
    "#for i, LR in enumerate(#TODO):\n",
    "#    plot_training_history(fn_out_history_1H(#TODO),\n",
    "#                          subtitle=\"lr\"+str(LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07354639-79a0-4ae6-a6bf-ddfa7cfe8dc3",
   "metadata": {},
   "source": [
    "Again, for the set of results shown above, we will ask a similar set of questions.\n",
    "\n",
    "**QUESTIONS**: Based on the plots shown above, inspect whether the training runs went as expected.\n",
    "\n",
    "1) Visually inspect for any anomalies. In the answer box below, mark the runs that produce \"abnormal training trends\", i.e. where the \"loss vs epochs\" and/or \"accuracy vs epochs\" curves exhibit a different behavior from what shown in the earlier 2-panel plot.\n",
    "\n",
    "2) Visually (or numerically) check for convergence (e.g. check the loss or accuracy for the last 4-5 epochs; what their slopes look like in this region; any fluctuations?)\n",
    "\n",
    "3) Observe the differences in the *final* accuracies as a result of different `learning_rate` values. What happens with the metrics as we use bigger and bigger learning rate? (We will do this more carefully in the next phase.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e77b2-c160-463e-a6d4-a9d807b5697b",
   "metadata": {},
   "source": [
    "> #### **ANSWERS**\n",
    ">\n",
    "> 1. #TODO\n",
    ">\n",
    "> 2. #TODO\n",
    ">\n",
    "> 3. #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08767a47-ad0a-416d-b155-c55ffd0f60d0",
   "metadata": {},
   "source": [
    "### Step 3: Create an Intermediate DataFrame for `learning_rate` Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8686e-0c64-4fde-83d6-8eff50e7943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use the same loop structure we used earlier to parse the history data,\n",
    "and create the temporary data structure which will be converted to\n",
    "a dataframe called `df_LR` below.\"\"\";\n",
    "\n",
    "#all_lastEpochMetrics = []\n",
    "## Fill in the rows for the DataFrame\n",
    "#for LR in listLR:\n",
    "#    # Read the history CSV file and get the last row's data,\n",
    "#    # which corresponds to the last epoch data.\n",
    "#    result_csv = #TODO\n",
    "#    print(\"Reading:\", result_csv)\n",
    "#    epochMetrics = pd.read_csv(result_csv)\n",
    "#    # Fetch the loss, accuracy, val_loss, and val_accuracy from the last epoch\n",
    "#    # (should be the last row in the CSV file unless there's something wrong\n",
    "#    # during the traning)\n",
    "#    lastEpochMetrics = epochMetrics.iloc[lastEpochNum, :].to_dict()\n",
    "#    # Attach the \"learning_rate\" value\n",
    "#    lastEpochMetrics[\"learning_rate\"] = #TODO\n",
    "#    all_lastEpochMetrics.append(lastEpochMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8b12c-8c89-4fb9-81d8-ab08e3e3f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Now construct df_LR:\"\"\";\n",
    "\n",
    "#df_LR = pd.DataFrame(all_lastEpochMetrics, #TODO)\n",
    "\n",
    "#df_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9606139-344c-41c6-a127-8b81c7ad2ff7",
   "metadata": {},
   "source": [
    "### Step 4: Save the Intermediate DataFrame (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76827867-cb03-41a9-8296-f92e7e20d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LR.to_csv(\"post_processing_hpc_lr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ba147-231e-4063-9394-9a58a7bb245b",
   "metadata": {},
   "source": [
    "## Batch Size Experiment\n",
    "\n",
    "Follow the same steps as before, please replicate the recipe to check the effect of `batch_size` hyperparameter.\n",
    "\n",
    "\n",
    "Now that we have laid a good foundation with the \"scan-hidden-neuron\" experiment,\n",
    "we will reapply the postprocessing to the \"learning rate\" experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a24c8-9c83-4c73-b768-628fd39301ca",
   "metadata": {},
   "source": [
    "### Step 1: Discover and Load the Results (BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc35cd-f7bc-434c-a026-9fc82ba33356",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l -d scan-batch-size/model_1H*N_lr*_bs*_e*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90911d24-0f9b-455c-b904-df051a3dc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Enter the batch sizes that you tried in your experiment,\n",
    "see the contents of the `submit-scan-batch-size.sh` script in your working directory.\"\"\";\n",
    "\n",
    "#dirPathBS = #TODO\n",
    "#listBS = [ #TODO ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a26fe3-fa0a-4fae-aa44-d82cd0a5ef70",
   "metadata": {},
   "source": [
    "### Step 2: Validation of Model Training: Visual Inspection (BS)\n",
    "\n",
    "Let's repeat the visual validation of model training runs for the scan over batch sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc471c-bdcc-49bc-a79b-034b0d7f0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The validation of model training for the batch size experiment\"\"\";\n",
    "\n",
    "#for i, BS in enumerate(#TODO):\n",
    "#    plot_training_history(fn_out_history_1H(#TODO),\n",
    "#                          subtitle=\"bs\"+str(BS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd059d6-2117-4163-83e7-a1f1c6ce9b6c",
   "metadata": {},
   "source": [
    "**QUESTIONS**: Based on the plots shown above, inspect whether the training runs went as expected.\n",
    "\n",
    "1) Visually inspect for any anomalies. In the answer box below, mark the runs that produce \"abnormal training trends\", i.e. where the \"loss vs epochs\" and/or \"accuracy vs epochs\" curves exhibit a different behavior from what shown in the first 2-panel plot in this notebook.\n",
    "\n",
    "2) Visually (or numerically) check for convergence (e.g. check the loss or accuracy for the last 4-5 epochs; what their slopes look like in this region; any fluctuations?)\n",
    "\n",
    "3) Observe the differences in the *final* accuracies as a result of different `batch_size` values. What happens with the metrics as we use bigger and bigger batch size? (We will do this more carefully in the next phase.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a96d1-33e3-4f80-bc94-4a6703f5a603",
   "metadata": {},
   "source": [
    "> #### **ANSWERS**\n",
    ">\n",
    "> 1. #TODO\n",
    ">\n",
    "> 2. #TODO\n",
    ">\n",
    "> 3. #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f6fb3-114f-445c-8cfa-63584a65bc77",
   "metadata": {},
   "source": [
    "### Step 3: Create an Intermediate DataFrame for `batch_size` Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337647f0-b9d7-4774-a417-4e648f0db54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use the same loop structure we used earlier to parse the history data,\n",
    "and create the temporary data structure which will be converted to\n",
    "a dataframe called `df_BS` below.\"\"\";\n",
    "\n",
    "#all_lastEpochMetrics = []\n",
    "## Fill in the rows for the DataFrame\n",
    "#for #TODO:\n",
    "#    # Read the history CSV file and get the last row's data,\n",
    "#    # which corresponds to the last epoch data.\n",
    "#    #TODO\n",
    "#    # Fetch the loss, accuracy, val_loss, and val_accuracy from the last epoch\n",
    "#    # (should be the last row in the CSV file unless there's something wrong\n",
    "#    # during the traning)\n",
    "#    #TODO\n",
    "#    # Attach the \"batch_size\" value\n",
    "#    #TODO\n",
    "#    all_lastEpochMetrics.append(lastEpochMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d11b3-2347-457e-ad64-26e6517db776",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lastEpochMetrics = []\n",
    "# Fill in the rows for the DataFrame\n",
    "for BS in listBS:\n",
    "    # Read the history CSV file and get the last row's data,\n",
    "    # which corresponds to the last epoch data.\n",
    "    result_csv = fn_out_history_1H(dirPathBS, 18, 0.0003, BS, 30)\n",
    "    print(\"Reading:\", result_csv)\n",
    "    epochMetrics = pd.read_csv(result_csv)\n",
    "    # Fetch the loss, accuracy, val_loss, and val_accuracy from the last epoch\n",
    "    # (should be the last row in the CSV file unless there's something wrong\n",
    "    # during the traning)\n",
    "    lastEpochMetrics = epochMetrics.iloc[lastEpochNum, :].to_dict()\n",
    "    # Attach the \"batch_size\" value\n",
    "    lastEpochMetrics[\"batch_size\"] = BS\n",
    "    all_lastEpochMetrics.append(lastEpochMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735a990-b23f-4458-a055-27f543eefcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Now construct df_BS:\"\"\";\n",
    "\n",
    "#df_BS = pd.DataFrame(all_lastEpochMetrics, #TODO)\n",
    "\n",
    "#df_BS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3edd5-8715-4a2f-b95d-913c68162ca7",
   "metadata": {},
   "source": [
    "### Step 4: Save the Intermediate DataFrame (BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9ebdb-91ee-4c4c-bac5-211a12aec6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BS.to_csv(\"post_processing_hpc_bs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859edd55-b8a1-4199-a0c5-b3625cd9a81c",
   "metadata": {},
   "source": [
    "## Multiple Hidden Layers Experiment (\"HL\")\n",
    "\n",
    "This experiment is different from the rest because now we alter the number of hidden neurons.\n",
    "In the suggested hyperparameters to try (during the batch job submissions),\n",
    "we vary only the number of hidden layers while fixing the number of neurons in each layer.\n",
    "This equals increasing the depth of the network.\n",
    "\n",
    "This experiment adds complexity in the naming convention.\n",
    "We use the following model code string to denote the number of hidden layers and the num of neurons in each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9efa90-3889-42b7-8194-5d1c6ad41d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layer_code_XH(hidden_neurons):\n",
    "    \"\"\"Constructs a model-layer code string (e.g. 1H18N, 2H32N18N, ...).\n",
    "    \"\"\"\n",
    "    hidden_neurons = list(hidden_neurons)\n",
    "    hn_str = str(len(hidden_neurons)) + \"H\" \\\n",
    "           + \"\".join(str(HN) + \"N\" for HN in hidden_neurons)\n",
    "    return hn_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d9648e-34e6-4fe0-80fd-9cb3d4798b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some\n",
    "\n",
    "model_layer_code_XH([18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8399f0-ed8c-4a0a-8b39-ce18428546b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layer_code_XH([32,18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d13be70-9bc6-45cf-b034-108a3576b0cb",
   "metadata": {},
   "source": [
    "### Step 1: Discover and Load the Results (HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0a059-146c-4587-a5c4-eedefe5048d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l -d scan-layers/model_*H*N_lr*_bs*_e*/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe457f-7f02-4201-bf61-a9a3c8b2360f",
   "metadata": {},
   "source": [
    "**EXERCISE** - Now create a list named `listHL` which contains the values of `hidden_neurons`'s used in your training runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0dd27-850d-46e7-909b-0693de7eb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Enter the hidden layers configuration that you tried in your experiment,\n",
    "see the contents of the `submit-scan-layers.sh` script in your working directory.\"\"\";\n",
    "\n",
    "#dirPathHL = #TODO\n",
    "#listHL = [ [18], [18,18], #TODO ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57caf087-2cc5-4024-aafe-4cf68e7990bf",
   "metadata": {},
   "source": [
    "### Step 2: Validation of Model Training: Visual Inspection (HL)\n",
    "\n",
    "Let's repeat the visual validation of model training runs for the scan over hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b9e73-7f92-4b43-b606-0930e7f1e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Repeat the validation of model training, but now for the learning rate experiment\"\"\";\n",
    "\n",
    "#for i, HL in enumerate(#TODO):\n",
    "#    plot_training_history(fn_out_history_XH(#TODO),\n",
    "#                          subtitle=\"hl\"+model_layer_code_XH(HL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c0126-d663-406a-81fe-3d2c9f954029",
   "metadata": {},
   "source": [
    "**QUESTIONS**: Based on the plots shown above, inspect whether the training runs went as expected.\n",
    "\n",
    "1) Visually inspect for any anomalies. In the answer box below, mark the runs that produce \"abnormal training trends\", i.e. where the \"loss vs epochs\" and/or \"accuracy vs epochs\" curves exhibit a different behavior from what shown in the first 2-panel plot near the top of this notebook.\n",
    "\n",
    "2) Visually (or numerically) check for convergence (e.g. check the loss or accuracy for the last 4-5 epochs; what their slopes look like in this region; any fluctuations?)\n",
    "\n",
    "3) Observe the differences in the *final* accuracies as a result of different `hidden_neurons` values. What happens with the metrics as we use deeper and deeper network? (We will do this more carefully in the next phase.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ce8c4-34fb-40e7-9434-0918c8a3fe2f",
   "metadata": {},
   "source": [
    "> #### **ANSWERS**\n",
    ">\n",
    "> 1. #TODO\n",
    ">\n",
    "> 2. #TODO\n",
    ">\n",
    "> 3. #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cda488-52e2-46a3-be40-d9fd96693ea2",
   "metadata": {},
   "source": [
    "### Step 3: Create an Intermediate DataFrame for `hidden_layers` Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d92019-2366-4f2d-935a-25c598308b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use the same loop structure we used earlier to parse the history data,\n",
    "and create the temporary data structure which will be converted to\n",
    "a dataframe called `df_HL` below.\"\"\";\n",
    "\n",
    "#all_lastEpochMetrics = []\n",
    "## Fill in the rows for the DataFrame\n",
    "#for HL in listHL:\n",
    "#    # Read the history CSV file and get the last row's data,\n",
    "#    # which corresponds to the last epoch data.\n",
    "#    #TODO\n",
    "#    # Fetch the loss, accuracy, val_loss, and val_accuracy from the last epoch\n",
    "#    # (should be the last row in the CSV file unless there's something wrong\n",
    "#    # during the traning)\n",
    "#    lastEpochMetrics = epochMetrics.iloc[lastEpochNum, :].to_dict()\n",
    "#    # Attach the \"hidden_neurons\" value\n",
    "#    lastEpochMetrics[\"hidden_neurons\"] = str(list(HL))\n",
    "#    all_lastEpochMetrics.append(lastEpochMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d83eaf-d793-4e0e-9c7b-c5e2b164cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Now construct df_HL:\"\"\";\n",
    "\n",
    "#df_HL = pd.DataFrame(all_lastEpochMetrics, #TODO)\n",
    "\n",
    "#df_HL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c86ac4-8f5d-4afe-8bdc-193198dc5e50",
   "metadata": {},
   "source": [
    "### Step 4: Save the Intermediate DataFrame (HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a6aae-f403-46cc-b122-3cba8efe0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HL.to_csv(\"post_processing_hpc_layers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1eaa0f-2244-4eb3-9ddf-425899e41e05",
   "metadata": {},
   "source": [
    "## END of Post-processing Stage\n",
    "\n",
    "Congratulations!\n",
    "You have completed the post-processing of all the experiments you did previously.\n",
    "In the next stage, we will perform analysis based on the post-processed result.\n",
    "We will learn a lot of things regarding the roles of the key hyperparameters (hidden layers, learning rate, and batch size) in neural network models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
