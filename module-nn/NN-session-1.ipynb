{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeapSECURE module 4: Deap Learning**\n",
    "\n",
    "# Session 1: Binary Classification\n",
    "\n",
    "Welcome to the DeapSECURE online training program!\n",
    "This is a Jupyter notebook for the hands-on learning activities of the\n",
    "[\"Deep Learning\" (DL) module](https://deapsecure.gitlab.io/deapsecure-lesson04-nn/), Episode 4: [\"An Introduction to Keras with Binary Classification Task\"](https://deapsecure.gitlab.io/deapsecure-lesson04-nn/20-keras-intro/index.html).\n",
    "Please visit the [DeapSECURE](https://deapsecure.gitlab.io/) website to learn more about our training program.\n",
    "\n",
    "In this notebook, we will learn how to use Keras framework to build a very simple \"binary classfication model\".\n",
    "We will build a one-neuron model to perform the \"application classification task\" using the SherLock's \"**2-apps**\" dataset introduced in the [\"Machine Learning\"](https://deapsecure.gitlab.io/deapsecure-lesson03-ml/) module.\n",
    "A single neuron is the simplest neural network model for this classification task, because there is only one output needed to distinguish the two different apps.\n",
    "\n",
    "\n",
    "**QUICK LINKS**\n",
    "* [Setup](#sec-setup)\n",
    "* [Loading Sherlock Data](#sec-Load_data)\n",
    "* [Binary Classification](#sec-Binary_clf)\n",
    "* [Examining the Performance of One-neuron Model for Binary Classification Task](#sec-examining_performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-setup\"></a>\n",
    "## 1. Setup Instructions\n",
    "\n",
    "If you are opening this notebook from the Wahab OnDemand interface, you're all set.\n",
    "\n",
    "If you see this notebook elsewhere, and want to perform the exercises on Wahab cluster, please follow the steps outlined in our setup procedure.\n",
    "\n",
    "1. Make sure you have activated your HPC service.\n",
    "2. Point your web browser to https://ondemand.wahab.hpc.odu.edu/ and sign in with your MIDAS ID and password.\n",
    "3. Create a new Jupyter session with the following parameters: Python version **3.7**, Python suite `tensorflow 2.6 + pytorch 1.10`, Number of Cores **4**, Number of GPU **0**, Partition `main`, and Number of Hours at least **4**. (See <a href=\"https://wiki.hpc.odu.edu/en/ood-jupyter\" target=\"_blank\">ODU HPC wiki</a> for more detailed help.)\n",
    "4. From the JupyterLab launcher, start a new Terminal session. Then issue the following commands to get the necessary files:\n",
    "\n",
    "       mkdir -p ~/CItraining/module-nn\n",
    "       cp -pr /shared/DeapSECURE/module-nn/. ~/CItraining/module-nn\n",
    "\n",
    "Using the file manager on the left sidebar, now change the working directory to `~/CItraining/module-nn`.\n",
    "The file name of this notebook is `NN-session-1.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reminder\n",
    "\n",
    "* Throughout this notebook, `#TODO` is used as a placeholder where you need to fill in with something appropriate. \n",
    "\n",
    "* To run a code in a cell, press `Shift+Enter`.\n",
    "\n",
    "* <a href=\"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\" target=\"_blank\">Pandas cheatsheet</a>\n",
    "\n",
    "* <a href=\"https://deapsecure.gitlab.io/deapsecure-lesson02-bd/10-pandas-intro/index.html#summary-indexing-syntax\" target=\"_blank\">Summary table of the commonly used indexing (subscripting) syntax</a> from our own lesson.\n",
    "\n",
    "* <a href=\"https://keras.io/api/\" target=\"_blank\">Keras API document</a>\n",
    "\n",
    "We recommend you open these on separate tabs or print them;\n",
    "they are handy help for writing your own codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading Python Libraries\n",
    "\n",
    "First step, we need to import the required libraries into this Jupyter Notebook:\n",
    "`pandas`, `numpy`,`matplotlib.pyplot`,`sklearn` and `tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import the necessary Python modules\"\"\";\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas\n",
    "import numpy\n",
    "#import seaborn\n",
    "from matplotlib import pyplot\n",
    "import sklearn\n",
    "\n",
    "# tools for machine learning:\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for evaluating model performance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# classic machine learning models:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Import Keras objects\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some advanced learners may like to use shortcuts,\n",
    "# so we give them here:\n",
    "pd = pandas\n",
    "np = numpy\n",
    "plt = pyplot\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Load_data\"></a>\n",
    "## 2. Loading Preprocessed SherLock \"2-apps\" dataset\n",
    "\n",
    "First, we load the SherLock's \"2-apps\" _preprocessed_ features and labels into DataFrames.\n",
    "We use the reduced set of features saved at the end of the \"Machine Learning\" module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_features = pd.read_csv('sherlock/2apps_4f/sherlock_2apps_features.csv')\n",
    "df2_labels = pd.read_csv('sherlock/2apps_4f/sherlock_2apps_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing and feature selection, we only have 4 features, namely: `cutime`,`num_threads`,`otherPrivateDirty`,`priority`. \n",
    "The label has two values: `0` representing **Facebook**, and `1` **WhatsApp**.\n",
    "\n",
    "As we do in the ML module, we first split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_F, test_F, train_L, test_L = train_test_split(df2_features, df2_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Binary_clf\"></a>\n",
    "## 3. Binary Classification Task in Keras\n",
    "\n",
    "Keras is a powerful, high-level framework to develop and deploy neural network models in Python.\n",
    "Keras is intuitive to use, allowing rapid prototyping, experimentation, as well as deployment of deep learning models for real-world problems.\n",
    "Keras began as a high-level interface to several lower-level software frameworks such as Theano and TensorFlow; however, newer versions are [built exclusively for TensorFlow](https://github.com/keras-team/keras/releases/tag/2.4.0).\n",
    "In this notebook, we show how easy it is to define, train, evaluate, and deploy neural networks with Keras.\n",
    "\n",
    "The steps involved in deep learning are very similar to the steps of traditional machine learning:\n",
    "\n",
    "1. Loading and preprocessing the input data;\n",
    "2. Defining a neural network model using Keras;\n",
    "3. Compiling the network (model);\n",
    "4. Fitting (training) the network using the training data;\n",
    "5. Evaluating the performance of the network;\n",
    "6. Improving the model's performance iteratively by adjusting the network's hyperparameters and retraining;\n",
    "7. Deploying the model to make predictions (i.e. \"inference\").\n",
    "\n",
    "Of these steps, the second and third steps will require the Keras-specific objects and functions.\n",
    "Keras model object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Defining a Neural Network the Keras Way\n",
    "\n",
    "**There are mainly two ways that we can build models in Keras:**\n",
    "\n",
    "* Sequential\n",
    "* Functional\n",
    "\n",
    "In this training, we limit ourselves to the Sequential model, which is sufficient to build simple neural network models.\n",
    "Please refer to [Keras documentation on the Sequential model](https://keras.io/guides/sequential_model/) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras organizes the objects in a logical way, in this way:\n",
    "* A neural network model consists of *layers* (at minimum, an input layer [always implied] and an output layer).\n",
    "* Each layer consists of one or more neurons (or generally, *nodes*).\n",
    "\n",
    "Keras library has many objects for the different types of layers.\n",
    "The `Dense` object defines a fully-connected neuron layers, which is the most basic type of layer.\n",
    "We will create neural network models using one or more `Dense` layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Constructing a Neural Network Model\n",
    "\n",
    "Let us create a neural network model with Keras.\n",
    "This model must have four inputs (defined by the four features in the SherLock \"2-apps\" data) and one output to distinguish between the two applications: Facebook and WhatsApp.\n",
    "We will create a `Sequential` object to represent the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a function to construct a neural network with Keras. \n",
    "This function will be called `NN_binary_clf` (*binary* for binary classification task; *clf* is the short for \"classifier\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_binary_clf(learning_rate):\n",
    "    \"\"\"Create a one-neuron binary classifier using Keras\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(1, activation='sigmoid', input_shape=(4,))\n",
    "    ])\n",
    "    adam = Adam(lr=learning_rate,\n",
    "                beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function builds a `Sequential` model (full object name: `tensorflow.keras.models.Sequential`).\n",
    "The model has only one layer defined by this declaration:\n",
    "\n",
    "```python\n",
    "Dense(1, activation='sigmoid', input_shape=(4,))\n",
    "```\n",
    "\n",
    "The `Dense` function declares a regular fully-connected neural layer, which can be a hidden layer or an output layer.\n",
    "The arguments have the following meaning:\n",
    "\n",
    "* `1`: the number of outputs from this layer, which also defines the number of fully connected neurons in this layer.\n",
    "\n",
    "* `activation='sigmoid'` defines the (nonlinear) activation function used to transform the weighted sum of the input values to the output values.\n",
    "\n",
    "* `input_shape=(4,)` defines that this layer connects to the input layer that has four inputs.\n",
    "\n",
    "Please see Keras' [documentation for the Dense layer](https://keras.io/api/layers/core_layers/dense/) for more information and additional parameters.\n",
    "\n",
    "In the `NN_binary_clf` function, this dense layer is the first and last layer in the model.\n",
    "\n",
    "The next line in the function above,\n",
    "\n",
    "```python\n",
    "adam = tf.keras.optimizers.Adam(lr=learning_rate,\n",
    "                                beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "```\n",
    "\n",
    "defines an *optimizer* to use to train the model, i.e. to minimize the loss function.\n",
    "We use the Adam optimizer, which is a \"stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments\" ([ref](https://keras.io/api/optimizers/adam/)).\n",
    "This is the go-to optimizer by many deep learning practitioners.\n",
    "The critical parameter here is the *learning rate*, which determines how fast the model \"learn\" based on the feedback from the previous iteration.\n",
    "\n",
    "The last line *compiles* the model, by integrating it with the other key component of a network, which is the *loss function*:\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "The loss function is one of the important components of neural networks. Loss is nothing but a prediction error of neural net. And the method to calculate the loss is called loss function. In simple words, the Loss is used to calculate the gradients. And gradients are used to update the weights of the Neural Net. This is how a Neural Net is trained. the followings are essential loss functions which could be used for most of the models. [(Source: Towardsdatascince)](https://towardsdatascience.com/understanding-different-loss-functions-for-neural-networks-dd1ed0274718)\n",
    "\n",
    "  * Mean Squared Error (MSE)\n",
    "  * Binary Crossentropy (BCE)\n",
    "  * Categorical Crossentropy (CC)\n",
    "  * Sparse Categorical Crossentropy (SCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model Fitting and Validation\n",
    "\n",
    "Then, we use a model object to call `NN_binary_clf` function and start the fitting process:\n",
    "\n",
    "* epochs: The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
    "\n",
    "* batch size: The number of examples from the training dataset used in the estimate of the error gradient is called the batch size and is an important hyperparameter that influences the dynamics of the learning algorithm.\n",
    "\n",
    "* Loss function used: `binary_crossentropy`\n",
    "\n",
    "* Optimizer used: Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_binary_clf(0.0003)\n",
    "model_history = model.fit(train_F, train_L,\n",
    "                          epochs=5, batch_size=32,\n",
    "                          validation_data=(test_F, test_L),\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Explanation of the Training Result\n",
    "\n",
    "`loss` and `val_loss` are the values of loss functions for your training and validation data, respectively.\n",
    "Similarly, `accuracy` is the accuracy on the training data and `val_accuracy` is the accuracy on the validation data.\n",
    "For model validation, we need to focus on the `val_loss` and `val_accuracy` values.\n",
    "\n",
    "**QUESTION**: Why are `val_loss` and `val_accuracy` are more important to pay attention to than the training data's metrics?\n",
    "\n",
    "**QUESTION**: What are the trends of `val_loss` and `val_accuracy` as we have more and more epochs?\n",
    "\n",
    "Model validation is already part of the Keras training function (`fit`); there is no need to invoke a separate validation function.\n",
    "\n",
    "This training output shows 5 iteration or epochs: in each epoch the model went through the all training data once to have the model parameters (neuron weights) adjusted to better fit the behavior of the training data.\n",
    "As the result shows, our first epochs took \\~20 seconds to complete (this timing varies based on the actual computer hardware used to run this training). The loss function drops down just below \\~0.35 and the accuracy is \\~0.85.\n",
    "\n",
    "Our model has only the input layer and output layer with no hidden layers in between; there is not much flexibility to account for the complexity embodied in the training data.\n",
    "Therefore, we should expect a fairly low accuracy outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-examining_performance\"></a>\n",
    "## 4. Examining the Performance of One-neuron Model for Binary Classification Task\n",
    "\n",
    "We've finished constructing our first model with keras. Now, let's compare the performance of our 1-neuron keras model against traditional machine learning outputs. We will construct a Decision Tree model and Logistic Regression model, both trained by scikit-learn, and then compare their accuracy on the same data with that of our 1-neuron model with keras.\n",
    "\n",
    "Before constructing our models, let us define a function to evaluate the accuracy of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model,test_F,test_L):\n",
    "    test_L_pred = model.predict(test_F)\n",
    "    print(\"Evaluation by using model:\",type(model).__name__)\n",
    "    print(\"accuracy_score:\",accuracy_score(test_L, test_L_pred))\n",
    "    print(\"confusion_matrix:\",\"\\n\",confusion_matrix(test_L, test_L_pred))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `model_evaluate` function to evaluate our models. Now, let's construct our decision tree and logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Construct a Decision Tree Model and fit to training data\"\"\";\n",
    "#TODO\n",
    "#model_dtc =\n",
    "#model_dtc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Construct a Logistic Regression Model and fit to training data\"\"\";\n",
    "#TODO\n",
    "#model_lr =\n",
    "#model_lr.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have constructed our Decision Tree and Logistic Regression models, we can compare their accuracy to our 1-nueron keras model by calling the `model_evaluate` function on our simple machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment and run\"\"\";\n",
    "#model_evaluate(model_dtc, test_F, test_L)\n",
    "#print()\n",
    "#model_evaluate(model_lr, test_F, test_L)\n",
    "#print()\n",
    "#print('1-Neuron model:', model.evaluate(test_F, test_L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Challenge: Improving Neuron Model\n",
    "\n",
    "**QUESTION**:\n",
    "Can you think of ways to improve the one-neuron model?\n",
    "You are welcome to try your ideas using more cells below, and share them with your fellow learners?\n",
    "\n",
    "We will learn more of these in latter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your responses here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "\n",
    "In this notebook, we learned how to:\n",
    "\n",
    "* import the necessary libraries;\n",
    "* load and preprocess our dataset;\n",
    "* define a neural network model using Keras;\n",
    "* fit (train) our model.\n",
    "\n",
    "Please summarize your findings below:\n",
    "\n",
    "1. Which model performed the best so far: decision tree, logistic regression or a single-neuron model?\n",
    "    \n",
    "2. Which model trained faster?\n",
    "\n",
    "3. Why in this example the single-neuron model performed as it did?\n",
    "\n",
    "4. How can we improve the performance of neural networks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
