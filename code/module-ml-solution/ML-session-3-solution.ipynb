{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Session-3 Solution: Tuning the Machine Learning Model\n",
    "\n",
    "This notebook provides complete solutions for the ML-session-3 exercises.\n",
    "It demonstrates feature selection techniques and model validation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for model evaluation\n",
    "def model_evaluate(model, test_F, test_L):\n",
    "    test_L_pred = model.predict(test_F)\n",
    "    print(\"Evaluation by using model:\", type(model).__name__)\n",
    "    print(\"Accuracy Score:\", accuracy_score(test_L, test_L_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(test_L, test_L_pred))\n",
    "    return accuracy_score(test_L, test_L_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Sherlock Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "df2 = pd.read_csv('sherlock/sherlock_mystery_2apps.csv')\n",
    "\n",
    "# Remove irrelevant feature(s)\n",
    "df2.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with missing values\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "# Remove duplicate features\n",
    "df2.drop('Mem', axis=1, inplace=True)\n",
    "\n",
    "# Separate labels from features\n",
    "df2_labels = df2['ApplicationName']\n",
    "df2_features = df2.drop('ApplicationName', axis=1)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(df2_features)\n",
    "df2_features_n = pd.DataFrame(scaler.transform(df2_features),\n",
    "                              columns=df2_features.columns,\n",
    "                              index=df2_features.index)\n",
    "\n",
    "# Create a backup for later use\n",
    "df2_features_n_backup = df2_features_n.copy()\n",
    "\n",
    "print(f\"Preprocessed dataset shape: {df2_features_n.shape}\")\n",
    "print(f\"Features: {df2_features_n.columns.tolist()}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df2_features_n.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection\n",
    "\n",
    "### 3.1 Histogram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram panel for all features\n",
    "plt.figure(figsize=(12.0, 9.0))\n",
    "for (i, col) in enumerate(df2_features_n.columns):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    plt.hist(df2_features_n[col], bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.title(col, fontweight='bold')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.75, wspace=0.35)\n",
    "plt.suptitle('Distribution of All Features', fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: Look for features with similar distributions - these may be duplicates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Separate features by application for comparison\n",
    "Apps = df2_labels.unique()\n",
    "indx_app = {}\n",
    "features_app = {}\n",
    "\n",
    "for app in Apps:\n",
    "    indx_app[app] = df2_labels[df2_labels == app].index\n",
    "    features_app[app] = df2_features_n.loc[indx_app[app]]\n",
    "\n",
    "print(f\"Applications: {Apps}\")\n",
    "print(f\"Facebook records: {len(features_app['Facebook'])}\")\n",
    "print(f\"WhatsApp records: {len(features_app['WhatsApp'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Create histogram panel colored by application\n",
    "plt.figure(figsize=(12.0, 9.0))\n",
    "for (i, col) in enumerate(df2_features_n.columns):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    for app in Apps:\n",
    "        plt.hist(features_app[app][col], bins=50, alpha=0.5, label=app)\n",
    "    plt.title(col, fontweight='bold')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.75, wspace=0.35)\n",
    "plt.suptitle('Feature Distributions by Application', fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Features with overlapping distributions between apps are less discriminative.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Compute correlation matrix\n",
    "df2_corr = df2_features_n.corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(df2_corr)\n",
    "print(\"\\nCorrelation values range from -1 (perfectly anti-correlated) to 1 (perfectly correlated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Visualize correlation matrix as heatmap\n",
    "plt.figure(figsize=(10.0, 10.0))\n",
    "sns.heatmap(df2_corr, annot=True, fmt='.2f', vmax=1, vmin=-1, square=True, \n",
    "            cmap=\"RdBu_r\", center=0, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Identify highly correlated feature pairs\n",
    "print(\"\\nHighly Correlated Feature Pairs (|correlation| > 0.8):\")\nprint(\"=\"*60)\n\n# Find pairs with high correlation\nhigh_corr_pairs = []\nfor i in range(len(df2_corr.columns)):\n    for j in range(i+1, len(df2_corr.columns)):\n        corr_val = df2_corr.iloc[i, j]\n        if abs(corr_val) > 0.8:\n            high_corr_pairs.append((\n                df2_corr.columns[i],\n                df2_corr.columns[j],\n                corr_val\n            ))\n            print(f\"{df2_corr.columns[i]:20s} <-> {df2_corr.columns[j]:20s}: {corr_val:7.4f}\")\n\nprint(\"\\nModerate Correlation Pairs (0.5 < |correlation| <= 0.8):\")\nprint(\"=\"*60)\nfor i in range(len(df2_corr.columns)):\n    for j in range(i+1, len(df2_corr.columns)):\n        corr_val = df2_corr.iloc[i, j]\n        if 0.5 < abs(corr_val) <= 0.8:\n            print(f\"{df2_corr.columns[i]:20s} <-> {df2_corr.columns[j]:20s}: {corr_val:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Remove Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Drop highly correlated duplicate features\n",
    "print(\"Removing highly correlated features: vsize, queue, guest_time\")\ndf2_features_n.drop(['vsize', 'queue', 'guest_time'], axis=1, inplace=True)\nprint(f\"Remaining features ({len(df2_features_n.columns)}): {df2_features_n.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Remove moderately correlated features\n",
    "print(\"Removing moderately correlated features: utime, cminflt\")\ndf2_features_n.drop(['utime', 'cminflt'], axis=1, inplace=True)\nprint(f\"Remaining features ({len(df2_features_n.columns)}): {df2_features_n.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Group Analysis by Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Recombine features with labels for group analysis\n",
    "df2_with_label = df2_features_n.copy()\ndf2_with_label['ApplicationName'] = df2_labels\n\nprint(\"Descriptive Statistics by Application:\")\nprint(\"=\"*80)\nfor col in df2_features_n.columns:\n    print(f\"\\n{col}:\")\n    print(df2_with_label.groupby('ApplicationName')[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Analyze feature discriminability\nprint(\"\\nFeature Discriminability Analysis:\")\nprint(\"=\"*80)\nfor col in df2_features_n.columns:\n    stats = df2_with_label.groupby('ApplicationName')[col].describe()\n    fb_mean = stats.loc['Facebook', 'mean']\n    wa_mean = stats.loc['WhatsApp', 'mean']\n    fb_std = stats.loc['Facebook', 'std']\n    wa_std = stats.loc['WhatsApp', 'std']\n    \n    # Calculate separation metric\n    separation = abs(fb_mean - wa_mean) / (fb_std + wa_std)\n    print(f\"\\n{col}:\")\n    print(f\"  Facebook mean: {fb_mean:8.4f} (std: {fb_std:8.4f})\")\n    print(f\"  WhatsApp mean: {wa_mean:8.4f} (std: {wa_std:8.4f})\")\n    print(f\"  Separation metric: {separation:8.4f} (higher = better discriminator)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Remove features with poor discriminability\nprint(\"\\nRemoving features with poor discriminability: CPU_USAGE, lru\")\ndf2_features_n.drop(['CPU_USAGE', 'lru'], axis=1, inplace=True)\nprint(f\"\\nFinal feature set ({len(df2_features_n.columns)}): {df2_features_n.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Feature Selection Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Save the selected features\ndf2_features_n1 = df2_features_n_backup[['cutime', 'num_threads', 'otherPrivateDirty', 'priority']]\n\n# Convert labels to numeric\nlabels_numeric = df2_labels.replace(['Facebook', 'WhatsApp'], [0, 1])\n\n# Save to CSV\nlabels_numeric.to_csv('sherlock_2apps_labels.csv', header=True, index=False)\ndf2_features_n1.to_csv('sherlock_2apps_features.csv', index=False)\n\nprint(\"Selected Features:\")\nprint(df2_features_n1.head(10))\nprint(f\"\\nShape: {df2_features_n1.shape}\")\nprint(f\"\\nFeatures saved to:\")\nprint(\"  - sherlock_2apps_features.csv\")\nprint(\"  - sherlock_2apps_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Validating with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Prepare data for training\nfeatures = df2_features_n1.copy()\nlabels = df2_labels.copy()\n\n# Train-test split\ntrain_F, test_F, train_L, test_L = train_test_split(features, labels, test_size=0.2, random_state=42)\n\nprint(f\"Training set: {train_F.shape}\")\nprint(f\"Test set: {test_F.shape}\")\nprint(f\"\\nFeatures used: {features.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Logistic Regression model\nmodel_lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n%time model_lr.fit(train_F, train_L)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOGISTIC REGRESSION - SELECTED FEATURES\")\nprint(\"=\"*60)\nacc_lr = model_evaluate(model_lr, test_F, test_L)\nprint(f\"\\nAccuracy: {acc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Decision Tree model\nmodel_dtc = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=8, random_state=42)\n%time model_dtc.fit(train_F, train_L)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"DECISION TREE - SELECTED FEATURES\")\nprint(\"=\"*60)\nacc_dtc = model_evaluate(model_dtc, test_F, test_L)\nprint(f\"\\nAccuracy: {acc_dtc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Better Validation: K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Implement k-fold cross-validation\nfrom sklearn.model_selection import KFold, cross_val_score\n\nkfold = KFold(n_splits=10, shuffle=True, random_state=42)\n\n# Logistic Regression with k-fold\nmodel_lr_kfold = LogisticRegression(solver='lbfgs', max_iter=1000)\nresults_lr_kfold = cross_val_score(model_lr_kfold, train_F, train_L, cv=kfold)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"K-FOLD CROSS-VALIDATION RESULTS (k=10)\")\nprint(\"=\"*60)\nprint(\"\\nLogistic Regression:\")\nprint(f\"  Individual fold accuracies: {results_lr_kfold}\")\nprint(f\"  Mean Accuracy: {results_lr_kfold.mean():.4f}\")\nprint(f\"  Std Deviation: {results_lr_kfold.std():.4f}\")\nprint(f\"  95% Confidence Interval: [{results_lr_kfold.mean() - 1.96*results_lr_kfold.std():.4f}, {results_lr_kfold.mean() + 1.96*results_lr_kfold.std():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Decision Tree with k-fold\nmodel_dtc_kfold = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=8, random_state=42)\nresults_dtc_kfold = cross_val_score(model_dtc_kfold, train_F, train_L, cv=kfold)\n\nprint(\"\\nDecision Tree:\")\nprint(f\"  Individual fold accuracies: {results_dtc_kfold}\")\nprint(f\"  Mean Accuracy: {results_dtc_kfold.mean():.4f}\")\nprint(f\"  Std Deviation: {results_dtc_kfold.std():.4f}\")\nprint(f\"  95% Confidence Interval: [{results_dtc_kfold.mean() - 1.96*results_dtc_kfold.std():.4f}, {results_dtc_kfold.mean() + 1.96*results_dtc_kfold.std():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Comparison and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Create comprehensive results summary\nresults_summary = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree'],\n    'Test Accuracy': [acc_lr, acc_dtc],\n    'K-Fold Mean': [results_lr_kfold.mean(), results_dtc_kfold.mean()],\n    'K-Fold Std': [results_lr_kfold.std(), results_dtc_kfold.std()]\n})\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"COMPREHENSIVE RESULTS SUMMARY\")\nprint(\"=\"*80)\nprint(results_summary.to_string(index=False))\nprint(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Visualize k-fold results\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: K-fold accuracies\nfolds = np.arange(1, 11)\naxes[0].plot(folds, results_lr_kfold, 'o-', label='Logistic Regression', linewidth=2, markersize=8)\naxes[0].plot(folds, results_dtc_kfold, 's-', label='Decision Tree', linewidth=2, markersize=8)\naxes[0].axhline(y=results_lr_kfold.mean(), color='blue', linestyle='--', alpha=0.5, label=f'LR Mean: {results_lr_kfold.mean():.4f}')\naxes[0].axhline(y=results_dtc_kfold.mean(), color='orange', linestyle='--', alpha=0.5, label=f'DTC Mean: {results_dtc_kfold.mean():.4f}')\naxes[0].set_xlabel('Fold Number', fontsize=12)\naxes[0].set_ylabel('Accuracy', fontsize=12)\naxes[0].set_title('K-Fold Cross-Validation Accuracies', fontsize=13, fontweight='bold')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\naxes[0].set_ylim([0.5, 1.0])\n\n# Plot 2: Mean accuracy with error bars\nmodels = ['Logistic\\nRegression', 'Decision\\nTree']\nmeans = [results_lr_kfold.mean(), results_dtc_kfold.mean()]\nstds = [results_lr_kfold.std(), results_dtc_kfold.std()]\ncolors = ['steelblue', 'coral']\n\nbars = axes[1].bar(models, means, yerr=stds, capsize=10, alpha=0.7, color=colors, edgecolor='black', linewidth=2)\naxes[1].set_ylabel('Accuracy', fontsize=12)\naxes[1].set_title('Mean Accuracy with Standard Deviation', fontsize=13, fontweight='bold')\naxes[1].set_ylim([0.5, 1.0])\naxes[1].grid(axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor i, (bar, mean, std) in enumerate(zip(bars, means, stds)):\n    axes[1].text(bar.get_x() + bar.get_width()/2, mean + std + 0.02,\n                f'{mean:.4f}\\nÂ±{std:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings and Discussion\n",
    "\n",
    "### Feature Selection Process:\n",
    "1. **Correlation Analysis**: Identified and removed highly correlated features (vsize, queue, guest_time, utime, cminflt)\n",
    "2. **Discriminability Analysis**: Removed features with poor separation between classes (CPU_USAGE, lru)\n",
    "3. **Final Feature Set**: cutime, num_threads, otherPrivateDirty, priority\n",
    "\n",
    "### Model Performance:\n",
    "- **Logistic Regression**: Consistent performance across folds\n",
    "- **Decision Tree**: Slightly better performance with lower variance\n",
    "\n",
    "### Validation Strategy:\n",
    "- **K-Fold Cross-Validation**: Provides more robust estimate of model performance\n",
    "- **Uncertainty Quantification**: Standard deviation shows model stability\n",
    "\n",
    "### Why Feature Selection Matters:\n",
    "1. **Reduces Overfitting**: Fewer features = simpler model\n",
    "2. **Improves Interpretability**: Easier to understand which features drive predictions\n",
    "3. **Reduces Computational Cost**: Faster training and inference\n",
    "4. **Removes Noise**: Irrelevant features can degrade performance\n",
    "\n",
    "### Cybersecurity Application:\n",
    "This approach can be used for:\n",
    "- **Malware Detection**: Identify malicious apps based on resource usage patterns\n",
    "- **Behavioral Analysis**: Detect anomalous application behavior\n",
    "- **Real-time Monitoring**: Classify running applications efficiently\n",
    "- **Threat Intelligence**: Build profiles of known malicious applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python3",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
