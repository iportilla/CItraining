{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "This notebook provides practical examples for the concepts covered in Episode 01: Introduction to Machine Learning.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the essence of machine learning\n",
    "- Learn the concepts of function, data, and learning process\n",
    "- Distinguish between supervised and unsupervised learning\n",
    "- Understand the ML lifecycle and key concepts like parameters vs hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ML as a Mathematical Function\n",
    "\n",
    "A machine learning model is essentially a mathematical function: `f(X) -> y`\n",
    "- Input: features (X)\n",
    "- Output: prediction (y)\n",
    "- All data must be converted to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Continuous vs Discrete Functions\n",
    "\n",
    "### 2.1 Regression (Continuous Output)\n",
    "Predicting continuous values like cyberthreat risk, network latency, or house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate synthetic regression data\n",
    "# Simulating cyberthreat risk prediction based on network features\n",
    "X_reg, y_reg = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Create and train a linear regression model\n",
    "model_reg = LinearRegression()\n",
    "model_reg.fit(X_reg, y_reg)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_reg = model_reg.predict(X_reg)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_reg, y_reg, alpha=0.6, label='Actual data')\n",
    "plt.plot(X_reg, y_pred_reg, color='red', linewidth=2, label='Model prediction')\n",
    "plt.xlabel('Network Feature (e.g., number of servers)')\n",
    "plt.ylabel('Cyberthreat Risk Score')\n",
    "plt.title('Regression: Continuous Output Example')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Model equation: y = {model_reg.coef_[0]:.4f} * X + {model_reg.intercept_:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Classification (Discrete Output)\n",
    "Predicting discrete categories like benign vs malicious network events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate synthetic classification data\n",
    "# Simulating network event classification (benign=0, malicious=1)\n",
    "X_clf, y_clf = make_classification(n_samples=200, n_features=2, n_informative=2,\n",
    "                                    n_redundant=0, random_state=42)\n",
    "\n",
    "# Create and train a logistic regression model\n",
    "model_clf = LogisticRegression(random_state=42)\n",
    "model_clf.fit(X_clf, y_clf)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_clf = model_clf.predict(X_clf)\n",
    "\n",
    "# Visualize decision boundary\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_clf[:, 0], X_clf[:, 1], c=y_clf, cmap='coolwarm', alpha=0.6)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Classification: Discrete Output Example (Benign vs Malicious)')\n",
    "plt.colorbar(scatter, label='Class (0=Benign, 1=Malicious)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "accuracy = accuracy_score(y_clf, y_pred_clf)\n",
    "print(f\"Classification Accuracy: {accuracy:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Supervised vs Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Supervised Learning: We have labels (y)\n",
    "print(\"=== SUPERVISED LEARNING ===\")\n",
    "print(f\"Training data shape: {X_clf.shape}\")\n",
    "print(f\"Labels shape: {y_clf.shape}\")\n",
    "print(f\"Sample labels: {y_clf[:5]}\")\n",
    "print()\n",
    "\n",
    "# Unsupervised Learning: We only have features (X), no labels\n",
    "print(\"=== UNSUPERVISED LEARNING ===\")\n",
    "print(f\"Training data shape: {X_clf.shape}\")\n",
    "print(\"No labels provided - algorithm finds structure in data\")\n",
    "print()\n",
    "\n",
    "# Example: K-means clustering (unsupervised)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_clf)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Supervised\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_clf[:, 0], X_clf[:, 1], c=y_clf, cmap='coolwarm', alpha=0.6)\n",
    "plt.title('Supervised: True Labels')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "# Unsupervised\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_clf[:, 0], X_clf[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "            c='red', marker='X', s=200, edgecolors='black', linewidths=2)\n",
    "plt.title('Unsupervised: K-means Clusters')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: The ML Lifecycle\n",
    "\n",
    "The machine learning process involves:\n",
    "1. **Train**: Adjust model parameters on training set\n",
    "2. **Validate**: Evaluate on validation set\n",
    "3. **Adjust**: Tune hyperparameters\n",
    "4. **Test**: Final evaluation on test set\n",
    "5. **Deploy**: Use model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_clf, y_clf, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Data Split for ML Lifecycle:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples (60%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples (20%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples (20%)\")\n",
    "print()\n",
    "print(\"IMPORTANT: Never mix training, validation, and test sets!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Parameters vs Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"=== PARAMETERS vs HYPERPARAMETERS ===\")\n",
    "print()\n",
    "print(\"PARAMETERS:\")\n",
    "print(\"- Learned automatically during training\")\n",
    "print(\"- Example: weights in linear regression\")\n",
    "print(f\"- Logistic Regression coefficients: {model_clf.coef_}\")\n",
    "print()\n",
    "print(\"HYPERPARAMETERS:\")\n",
    "print(\"- Set before training, not learned automatically\")\n",
    "print(\"- Require manual tuning based on validation performance\")\n",
    "print()\n",
    "\n",
    "# Example: Decision Tree with different hyperparameters\n",
    "print(\"Decision Tree Hyperparameters:\")\n",
    "dt1 = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "dt2 = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "dt1.fit(X_train, y_train)\n",
    "dt2.fit(X_train, y_train)\n",
    "\n",
    "acc1_train = accuracy_score(y_train, dt1.predict(X_train))\n",
    "acc1_val = accuracy_score(y_val, dt1.predict(X_val))\n",
    "\n",
    "acc2_train = accuracy_score(y_train, dt2.predict(X_train))\n",
    "acc2_val = accuracy_score(y_val, dt2.predict(X_val))\n",
    "\n",
    "print(f\"\\nModel 1 (max_depth=2):\")\n",
    "print(f\"  Training accuracy: {acc1_train:.4f}\")\n",
    "print(f\"  Validation accuracy: {acc1_val:.4f}\")\n",
    "\n",
    "print(f\"\\nModel 2 (max_depth=10):\")\n",
    "print(f\"  Training accuracy: {acc2_train:.4f}\")\n",
    "print(f\"  Validation accuracy: {acc2_val:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Bias-Variance Tradeoff (Underfitting vs Overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demonstrate underfitting, overfitting, and good fit\n",
    "max_depths = [1, 3, 10, 20]\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    train_accs.append(accuracy_score(y_train, dt.predict(X_train)))\n",
    "    val_accs.append(accuracy_score(y_val, dt.predict(X_val)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths, train_accs, marker='o', label='Training Accuracy', linewidth=2)\n",
    "plt.plot(max_depths, val_accs, marker='s', label='Validation Accuracy', linewidth=2)\n",
    "plt.xlabel('Tree Depth (Hyperparameter)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Bias-Variance Tradeoff: Underfitting vs Overfitting')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(max_depths)\n",
    "plt.ylim([0.5, 1.05])\n",
    "\n",
    "# Annotate regions\n",
    "plt.axvspan(0.5, 2, alpha=0.1, color='red', label='Underfitting')\n",
    "plt.axvspan(2, 5, alpha=0.1, color='green', label='Good Fit')\n",
    "plt.axvspan(5, 20.5, alpha=0.1, color='orange', label='Overfitting')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Bias-Variance Analysis:\")\n",
    "for i, depth in enumerate(max_depths):\n",
    "    gap = train_accs[i] - val_accs[i]\n",
    "    print(f\"Depth {depth}: Train={train_accs[i]:.4f}, Val={val_accs[i]:.4f}, Gap={gap:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Evaluation Metrics - Precision, Recall, and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Use the best model for evaluation\n",
    "best_dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "best_dt.fit(X_train, y_train)\n",
    "y_pred_test = best_dt.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print(\"=== EVALUATION METRICS ===\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f} (avoid false positives)\")\n",
    "print(f\"Recall: {recall:.4f} (find all positive cases)\")\n",
    "print()\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Benign', 'Malicious'],\n",
    "            yticklabels=['Benign', 'Malicious'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion Matrix Interpretation:\")\n",
    "print(f\"True Negatives (TN): {cm[0, 0]} - Correctly identified benign\")\n",
    "print(f\"False Positives (FP): {cm[0, 1]} - Benign misclassified as malicious\")\n",
    "print(f\"False Negatives (FN): {cm[1, 0]} - Malicious misclassified as benign\")\n",
    "print(f\"True Positives (TP): {cm[1, 1]} - Correctly identified malicious\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key Takeaways:\n",
    "1. **ML is a function**: f(X) -> y, where X are features and y is the prediction\n",
    "2. **Two main types**: Regression (continuous) and Classification (discrete)\n",
    "3. **Supervised vs Unsupervised**: Supervised has labels, unsupervised finds patterns\n",
    "4. **ML Lifecycle**: Train \u2192 Validate \u2192 Adjust \u2192 Test \u2192 Deploy\n",
    "5. **Parameters vs Hyperparameters**: Parameters are learned, hyperparameters are tuned\n",
    "6. **Bias-Variance**: Balance between underfitting and overfitting\n",
    "7. **Evaluation**: Use appropriate metrics (accuracy, precision, recall) for your problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}