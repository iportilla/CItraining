{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN-Session-1 Solution: Binary Classification with Keras\n",
    "\n",
    "This notebook provides complete solutions for the NN-session-1 exercises.\n",
    "It demonstrates how to build a simple neural network for binary classification using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.13.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Preprocessed Sherlock Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (612114, 4)\n",
      "Labels shape: (612114, 1)\n",
      "\n",
      "Features: ['cutime', 'num_threads', 'otherPrivateDirty', 'priority']\n",
      "\n",
      "First 5 rows of features:\n",
      "     cutime  num_threads  otherPrivateDirty  priority\n",
      "0 -0.429029    -1.300898          -0.780597  0.246368\n",
      "1 -0.429029     0.222698          -0.688933  0.246368\n",
      "2 -0.429029    -0.292636          -0.321111  0.246368\n",
      "3 -0.429029    -1.300898          -0.785560  0.246368\n",
      "4 -0.429029     0.222698          -0.687036  0.246368\n",
      "\n",
      "Label distribution:\n",
      "ApplicationName\n",
      "0                  379054\n",
      "1                  233060\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed features and labels\n",
    "df2_features = pd.read_csv('../sherlock/2apps_4f/sherlock_2apps_features.csv')\n",
    "df2_labels = pd.read_csv('../sherlock/2apps_4f/sherlock_2apps_labels.csv')\n",
    "\n",
    "print(f\"Features shape: {df2_features.shape}\")\n",
    "print(f\"Labels shape: {df2_labels.shape}\")\n",
    "print(f\"\\nFeatures: {df2_features.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 rows of features:\")\n",
    "print(df2_features.head())\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df2_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (489691, 4)\n",
      "Test set: (122423, 4)\n",
      "\n",
      "Training labels distribution:\n",
      "ApplicationName\n",
      "0                  303142\n",
      "1                  186549\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test labels distribution:\n",
      "ApplicationName\n",
      "0                  75912\n",
      "1                  46511\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Split data into training and testing sets\n",
    "train_F, test_F, train_L, test_L = train_test_split(df2_features, df2_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {train_F.shape}\")\n",
    "print(f\"Test set: {test_F.shape}\")\n",
    "print(f\"\\nTraining labels distribution:\")\n",
    "print(train_L.value_counts())\n",
    "print(f\"\\nTest labels distribution:\")\n",
    "print(test_L.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a One-Neuron Binary Classifier with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function NN_binary_clf created successfully!\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Define a function to create a one-neuron binary classifier\n",
    "def NN_binary_clf(learning_rate=0.0003):\n",
    "    \"\"\"\n",
    "    Create a one-neuron binary classifier using Keras.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    learning_rate : float\n",
    "        Learning rate for the Adam optimizer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : Sequential\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(1, activation='sigmoid', input_shape=(4,))\n",
    "    ])\n",
    "    \n",
    "    # Create Adam optimizer with specified learning rate\n",
    "    adam = Adam(learning_rate=learning_rate,\n",
    "                beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Function NN_binary_clf created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> (20.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5\u001b[0m (20.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> (20.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5\u001b[0m (20.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Create and display model architecture\n",
    "model = NN_binary_clf(learning_rate=0.0003)\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(\"=\"*60)\n",
    "model.summary()\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the one-neuron model...\n",
      "============================================================\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Train the model\n",
    "print(\"Training the one-neuron model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_history = model.fit(train_F, train_L,\n",
    "                          epochs=20, batch_size=32,\n",
    "                          validation_data=(test_F, test_L),\n",
    "                          verbose=1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot loss\n",
    "axes[0].plot(model_history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(model_history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Model Loss Over Epochs', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy\n",
    "axes[1].plot(model_history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[1].plot(model_history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Model Accuracy Over Epochs', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTraining History Summary:\")\n",
    "print(f\"Initial Training Loss: {model_history.history['loss'][0]:.4f}\")\n",
    "print(f\"Final Training Loss: {model_history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Initial Validation Loss: {model_history.history['val_loss'][0]:.4f}\")\n",
    "print(f\"Final Validation Loss: {model_history.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"\\nInitial Training Accuracy: {model_history.history['accuracy'][0]:.4f}\")\n",
    "print(f\"Final Training Accuracy: {model_history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Initial Validation Accuracy: {model_history.history['val_accuracy'][0]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {model_history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Evaluate Keras model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KERAS ONE-NEURON MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_F, test_L, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "test_pred_keras = (model.predict(test_F) > 0.5).astype(int).flatten()\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(test_L, test_pred_keras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with Traditional ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Helper function for model evaluation\n",
    "def model_evaluate(model, test_F, test_L, model_name=\"\"):\n",
    "    \"\"\"\n",
    "    Evaluate a scikit-learn model.\n",
    "    \"\"\"\n",
    "    test_L_pred = model.predict(test_F)\n",
    "    acc = accuracy_score(test_L, test_L_pred)\n",
    "    cm = confusion_matrix(test_L, test_L_pred)\n",
    "    \n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Decision Tree model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DECISION TREE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_dtc = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=8, random_state=42)\n",
    "model_dtc.fit(train_F, train_L)\n",
    "\n",
    "acc_dtc, cm_dtc = model_evaluate(model_dtc, test_F, test_L, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Logistic Regression model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOGISTIC REGRESSION MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_lr = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
    "model_lr.fit(train_F, train_L)\n",
    "\n",
    "acc_lr, cm_lr = model_evaluate(model_lr, test_F, test_L, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['One-Neuron NN (Keras)', 'Decision Tree', 'Logistic Regression'],\n",
    "    'Test Accuracy': [test_accuracy, acc_dtc, acc_lr]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = comparison_df['Test Accuracy'].idxmax()\n",
    "best_model = comparison_df.loc[best_model_idx, 'Model']\n",
    "best_accuracy = comparison_df.loc[best_model_idx, 'Test Accuracy']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Visualize model comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "models = comparison_df['Model']\n",
    "accuracies = comparison_df['Test Accuracy']\n",
    "colors = ['steelblue', 'coral', 'lightgreen']\n",
    "\n",
    "bars = ax.bar(models, accuracies, color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings and Discussion\n",
    "\n",
    "### Observations:\n",
    "\n",
    "1. **Model Performance**: The one-neuron Keras model achieves comparable accuracy to traditional ML models.\n",
    "\n",
    "2. **Training Dynamics**: \n",
    "   - The Keras model shows convergence over epochs\n",
    "   - Validation accuracy stabilizes after several epochs\n",
    "   - No significant overfitting observed\n",
    "\n",
    "3. **Comparison with Traditional ML**:\n",
    "   - Decision Tree and Logistic Regression provide baseline performance\n",
    "   - One-neuron NN is essentially equivalent to logistic regression\n",
    "   - All models achieve similar accuracy on this dataset\n",
    "\n",
    "### Why Validation Metrics Matter:\n",
    "\n",
    "- **Training metrics** show how well the model fits the training data\n",
    "- **Validation metrics** show how well the model generalizes to unseen data\n",
    "- Validation metrics are more important for assessing true model performance\n",
    "- Large gap between training and validation metrics indicates overfitting\n",
    "\n",
    "### Ways to Improve the One-Neuron Model:\n",
    "\n",
    "1. **Add Hidden Layers**: Increase model capacity with hidden layers\n",
    "2. **Adjust Learning Rate**: Fine-tune the learning rate for better convergence\n",
    "3. **Increase Epochs**: Train for more epochs to improve convergence\n",
    "4. **Batch Size Tuning**: Experiment with different batch sizes\n",
    "5. **Regularization**: Add L1/L2 regularization to prevent overfitting\n",
    "6. **Feature Engineering**: Create more discriminative features\n",
    "\n",
    "### Cybersecurity Application:\n",
    "\n",
    "This binary classification approach can be used for:\n",
    "- **Malware Detection**: Classify applications as benign or malicious\n",
    "- **Anomaly Detection**: Identify unusual application behavior\n",
    "- **Real-time Monitoring**: Classify running applications on mobile devices\n",
    "- **Threat Intelligence**: Build profiles of known malicious applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb-test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
