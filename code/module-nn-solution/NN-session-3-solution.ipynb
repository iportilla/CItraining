{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN-Session-3 Solution: Advanced Neural Network Tuning\n",
    "\n",
    "This notebook provides complete solutions for the NN-session-3 exercises.\n",
    "It demonstrates advanced techniques for tuning neural networks to achieve high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with >50.0% missing values: ['cminflt']\n",
      "Numeric features: 16 columns\n",
      "Categorical features: 1 columns\n",
      "\n",
      "Training set: (218461, 20)\n",
      "Test set: (54616, 20)\n",
      "Number of classes: 18\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Load and preprocess 18-apps dataset\n",
    "df = pd.read_csv(\"../sherlock/sherlock_18apps.csv\", index_col=0)\n",
    "\n",
    "# Data cleaning\n",
    "df2 = df.copy()\n",
    "df2 = df2.drop(['Unnamed: 0'], axis=1, errors='ignore')\n",
    "\n",
    "# Drop columns with too many missing values (>50% missing)\n",
    "missing_threshold = 0.5\n",
    "missing_percent = df2.isna().sum() / len(df2)\n",
    "cols_to_drop = missing_percent[missing_percent > missing_threshold].index.tolist()\n",
    "print(f\"Columns with >{missing_threshold*100}% missing values: {cols_to_drop}\")\n",
    "df2 = df2.drop(columns=cols_to_drop)\n",
    "\n",
    "# Remove rows with remaining missing values\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "# Separate labels and features\n",
    "labels = df2['ApplicationName']\n",
    "df_features = df2.drop('ApplicationName', axis=1)\n",
    "\n",
    "# Feature scaling - handle numeric and categorical features separately\n",
    "numeric_features = df_features.select_dtypes(include=[np.number])\n",
    "categorical_features = df_features.select_dtypes(exclude=[np.number])\n",
    "\n",
    "print(f\"Numeric features: {numeric_features.shape[1]} columns\")\n",
    "print(f\"Categorical features: {categorical_features.shape[1]} columns\")\n",
    "\n",
    "# Scale only numeric features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(numeric_features)\n",
    "numeric_features_n = pd.DataFrame(scaler.transform(numeric_features),\n",
    "                                   columns=numeric_features.columns,\n",
    "                                   index=numeric_features.index)\n",
    "\n",
    "# Combine scaled numeric features with categorical features\n",
    "if categorical_features.shape[1] > 0:\n",
    "    df_features_n = pd.concat([numeric_features_n, categorical_features], axis=1)\n",
    "else:\n",
    "    df_features_n = numeric_features_n\n",
    "\n",
    "# One-hot encoding\n",
    "df_labels_onehot = pd.get_dummies(labels)\n",
    "df_features_encoded = pd.get_dummies(df_features_n)\n",
    "\n",
    "# Train-test split\n",
    "train_F, test_F, train_L, test_L = train_test_split(\n",
    "    df_features_encoded, df_labels_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {train_F.shape}\")\n",
    "print(f\"Test set: {test_F.shape}\")\n",
    "print(f\"Number of classes: {train_L.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model creation function defined!\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Define function to create models with different architectures\n",
    "def create_model(hidden_layers=[128, 64, 32], dropout_rate=0.2, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Create a neural network with specified architecture.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hidden_layers : list\n",
    "        Number of units in each hidden layer\n",
    "    dropout_rate : float\n",
    "        Dropout rate for regularization\n",
    "    learning_rate : float\n",
    "        Learning rate for optimizer\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer and first hidden layer\n",
    "    model.add(Dense(hidden_layers[0], activation='relu', input_shape=(train_F.shape[1],)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Additional hidden layers\n",
    "    for units in hidden_layers[1:]:\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(train_L.shape[1], activation='softmax'))\n",
    "    \n",
    "    # Compile\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Model creation function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPERIMENT 1: BASELINE MODEL\n",
      "============================================================\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">594</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m594\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,514</span> (56.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,514\u001b[0m (56.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,066</span> (54.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,066\u001b[0m (54.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION: Baseline model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 1: BASELINE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_baseline = create_model(hidden_layers=[128, 64, 32], dropout_rate=0.2, learning_rate=0.001)\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "model_baseline.summary()\n",
    "\n",
    "history_baseline = model_baseline.fit(\n",
    "    train_F, train_L,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=(test_F, test_L),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model_baseline.evaluate(test_F, test_L, verbose=0)\n",
    "print(f\"\\nBaseline Model Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Deeper Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Deeper network\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 2: DEEPER NETWORK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_deep = create_model(hidden_layers=[256, 128, 64, 32], dropout_rate=0.3, learning_rate=0.001)\n",
    "\n",
    "history_deep = model_deep.fit(\n",
    "    train_F, train_L,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=(test_F, test_L),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_acc_deep = model_deep.evaluate(test_F, test_L, verbose=0)\n",
    "print(f\"Deeper Network Accuracy: {test_acc_deep:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Wider Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Wider network\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 3: WIDER NETWORK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_wide = create_model(hidden_layers=[512, 256, 128], dropout_rate=0.2, learning_rate=0.001)\n",
    "\n",
    "history_wide = model_wide.fit(\n",
    "    train_F, train_L,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=(test_F, test_L),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_acc_wide = model_wide.evaluate(test_F, test_L, verbose=0)\n",
    "print(f\"Wider Network Accuracy: {test_acc_wide:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Different Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Different learning rate\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 4: DIFFERENT LEARNING RATE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_lr = create_model(hidden_layers=[256, 128, 64], dropout_rate=0.2, learning_rate=0.0005)\n",
    "\n",
    "history_lr = model_lr.fit(\n",
    "    train_F, train_L,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=(test_F, test_L),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_acc_lr = model_lr.evaluate(test_F, test_L, verbose=0)\n",
    "print(f\"Lower Learning Rate Accuracy: {test_acc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: With Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Model with early stopping\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT 5: WITH EARLY STOPPING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_es = create_model(hidden_layers=[256, 128, 64, 32], dropout_rate=0.2, learning_rate=0.001)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "\n",
    "history_es = model_es.fit(\n",
    "    train_F, train_L,\n",
    "    epochs=100, batch_size=32,\n",
    "    validation_data=(test_F, test_L),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_acc_es = model_es.evaluate(test_F, test_L, verbose=0)\n",
    "print(f\"With Early Stopping Accuracy: {test_acc_es:.4f}\")\n",
    "print(f\"Epochs trained: {len(history_es.history['loss'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Create comprehensive comparison\n",
    "results = pd.DataFrame({\n",
    "    'Experiment': [\n",
    "        'Baseline (128-64-32)',\n",
    "        'Deeper (256-128-64-32)',\n",
    "        'Wider (512-256-128)',\n",
    "        'Lower LR (0.0005)',\n",
    "        'Early Stopping'\n",
    "    ],\n",
    "    'Architecture': [\n",
    "        '[128, 64, 32]',\n",
    "        '[256, 128, 64, 32]',\n",
    "        '[512, 256, 128]',\n",
    "        '[256, 128, 64]',\n",
    "        '[256, 128, 64, 32]'\n",
    "    ],\n",
    "    'Learning Rate': [0.001, 0.001, 0.001, 0.0005, 0.001],\n",
    "    'Test Accuracy': [test_acc, test_acc_deep, test_acc_wide, test_acc_lr, test_acc_es]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_idx = results['Test Accuracy'].idxmax()\n",
    "print(f\"\\nBest Model: {results.loc[best_idx, 'Experiment']}\")\n",
    "print(f\"Best Accuracy: {results.loc[best_idx, 'Test Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Visualize training history comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "histories = [\n",
    "    ('Baseline', history_baseline),\n",
    "    ('Deeper', history_deep),\n",
    "    ('Wider', history_wide),\n",
    "    ('Lower LR', history_lr),\n",
    "    ('Early Stopping', history_es)\n",
    "]\n",
    "\n",
    "for idx, (name, history) in enumerate(histories):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(history.history['accuracy'], label='Training', linewidth=2)\n",
    "    ax.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    ax.set_title(f'{name}', fontweight='bold')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Bar chart comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = ['steelblue', 'coral', 'lightgreen', 'gold', 'plum']\n",
    "bars = ax.bar(range(len(results)), results['Test Accuracy'], color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "ax.set_title('Neural Network Tuning: Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(range(len(results)))\n",
    "ax.set_xticklabels(results['Experiment'], rotation=15, ha='right')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.axhline(y=0.99, color='red', linestyle='--', linewidth=2, label='Target (99%)')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "for bar, acc in zip(bars, results['Test Accuracy']):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Analyze impact of different hyperparameters\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HYPERPARAMETER IMPACT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Network Depth Impact:\")\n",
    "print(f\"   Baseline (3 layers): {test_acc:.4f}\")\n",
    "print(f\"   Deeper (4 layers): {test_acc_deep:.4f}\")\n",
    "print(f\"   Impact: {(test_acc_deep - test_acc)*100:+.2f}%\")\n",
    "\n",
    "print(\"\\n2. Network Width Impact:\")\n",
    "print(f\"   Baseline (128-64-32): {test_acc:.4f}\")\n",
    "print(f\"   Wider (512-256-128): {test_acc_wide:.4f}\")\n",
    "print(f\"   Impact: {(test_acc_wide - test_acc)*100:+.2f}%\")\n",
    "\n",
    "print(\"\\n3. Learning Rate Impact:\")\n",
    "print(f\"   Standard (0.001): {test_acc:.4f}\")\n",
    "print(f\"   Lower (0.0005): {test_acc_lr:.4f}\")\n",
    "print(f\"   Impact: {(test_acc_lr - test_acc)*100:+.2f}%\")\n",
    "\n",
    "print(\"\\n4. Early Stopping Impact:\")\n",
    "print(f\"   Without: {test_acc:.4f}\")\n",
    "print(f\"   With: {test_acc_es:.4f}\")\n",
    "print(f\"   Impact: {(test_acc_es - test_acc)*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Findings and Recommendations\n",
    "\n",
    "### Observations:\n",
    "\n",
    "1. **Network Architecture**:\n",
    "   - Deeper networks can capture more complex patterns\n",
    "   - Wider networks provide more capacity per layer\n",
    "   - Balance is key - too deep/wide can lead to overfitting\n",
    "\n",
    "2. **Learning Rate**:\n",
    "   - Lower learning rates allow finer convergence\n",
    "   - May require more epochs to converge\n",
    "   - Adaptive methods (Adam) help with convergence\n",
    "\n",
    "3. **Regularization**:\n",
    "   - Dropout prevents overfitting\n",
    "   - Batch normalization stabilizes training\n",
    "   - Early stopping prevents unnecessary training\n",
    "\n",
    "4. **Callbacks**:\n",
    "   - Early stopping saves training time\n",
    "   - Learning rate reduction helps fine-tuning\n",
    "   - Combination of callbacks improves results\n",
    "\n",
    "### Recommendations for Achieving >99% Accuracy:\n",
    "\n",
    "1. **Increase Model Capacity**: Use deeper/wider networks\n",
    "2. **Fine-tune Learning Rate**: Use adaptive learning rate schedules\n",
    "3. **Add Regularization**: Use dropout and batch normalization\n",
    "4. **Use Callbacks**: Implement early stopping and LR reduction\n",
    "5. **Data Augmentation**: Generate synthetic training data\n",
    "6. **Ensemble Methods**: Combine multiple models\n",
    "7. **Feature Engineering**: Create more discriminative features\n",
    "\n",
    "### Cybersecurity Applications:\n",
    "\n",
    "- **High-Accuracy Classification**: Critical for security systems\n",
    "- **Malware Detection**: Requires >99% accuracy to minimize false negatives\n",
    "- **Behavioral Analysis**: Detect anomalous application behavior\n",
    "- **Real-time Monitoring**: Efficient models for mobile deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb-test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
