{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN-Session-2 Solution: Multi-Class Classification with Keras\n",
    "\n",
    "This notebook provides complete solutions for the NN-session-2 exercises.\n",
    "It demonstrates how to build neural networks for multi-class classification using Keras on the 18-apps dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and Exploring the 18-Apps Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (273129, 19)\n",
      "\n",
      "First few rows:\n",
      "   ApplicationName  CPU_USAGE  UidRxBytes  UidRxPackets  UidTxBytes  \\\n",
      "0            Gmail       0.13           0             0           0   \n",
      "6         Hangouts       1.65           0             0           0   \n",
      "11       Messenger       0.21           0             0           0   \n",
      "18        Geo News       0.03           0             0           0   \n",
      "19        Facebook       0.20           0             0           0   \n",
      "\n",
      "    UidTxPackets  cutime  guest_time  importance  lru  num_threads  \\\n",
      "0              0     0.0         0.0         400   15         32.0   \n",
      "6              0     0.0         0.0         400   15         17.0   \n",
      "11             0     0.0         0.0         300    0         72.0   \n",
      "18             0     0.0         0.0         300    0         14.0   \n",
      "19             0     0.0         0.0         300    0         77.0   \n",
      "\n",
      "    otherPrivateDirty  priority      rss state  stime  utime         vsize  \\\n",
      "0                8300      20.0  10957.0     S  180.0  311.0  2.064265e+09   \n",
      "6               27284      20.0  20043.0     S   67.0  210.0  2.047980e+09   \n",
      "11              11324      20.0  13891.0     S  395.0  542.0  2.106794e+09   \n",
      "18                860      20.0   5694.0     S   43.0   39.0  1.893417e+09   \n",
      "19               5776      20.0   8511.0     S  401.0  464.0  2.204619e+09   \n",
      "\n",
      "    cminflt  \n",
      "0       NaN  \n",
      "6       NaN  \n",
      "11      NaN  \n",
      "18      NaN  \n",
      "19      NaN  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 273129 entries, 0 to 999994\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   ApplicationName    273129 non-null  object \n",
      " 1   CPU_USAGE          273077 non-null  float64\n",
      " 2   UidRxBytes         273129 non-null  int64  \n",
      " 3   UidRxPackets       273129 non-null  int64  \n",
      " 4   UidTxBytes         273129 non-null  int64  \n",
      " 5   UidTxPackets       273129 non-null  int64  \n",
      " 6   cutime             273077 non-null  float64\n",
      " 7   guest_time         273077 non-null  float64\n",
      " 8   importance         273129 non-null  int64  \n",
      " 9   lru                273129 non-null  int64  \n",
      " 10  num_threads        273077 non-null  float64\n",
      " 11  otherPrivateDirty  273129 non-null  int64  \n",
      " 12  priority           273077 non-null  float64\n",
      " 13  rss                273077 non-null  float64\n",
      " 14  state              273077 non-null  object \n",
      " 15  stime              273077 non-null  float64\n",
      " 16  utime              273077 non-null  float64\n",
      " 17  vsize              273077 non-null  float64\n",
      " 18  cminflt            0 non-null       float64\n",
      "dtypes: float64(10), int64(7), object(2)\n",
      "memory usage: 41.7+ MB\n",
      "\n",
      "Basic Statistics:\n",
      "                      count          mean           std    min           25%  \\\n",
      "CPU_USAGE          273077.0  6.618322e-01  3.207833e+00    0.0  5.000000e-02   \n",
      "UidRxBytes         273129.0  3.922973e+02  3.693198e+04 -280.0  0.000000e+00   \n",
      "UidRxPackets       273129.0  4.204643e-01  2.790607e+01  -11.0  0.000000e+00   \n",
      "UidTxBytes         273129.0  2.454729e+02  2.977305e+04  -60.0  0.000000e+00   \n",
      "UidTxPackets       273129.0  3.878826e-01  2.420920e+01   -1.0  0.000000e+00   \n",
      "cutime             273077.0  3.279844e-01  1.768488e+00    0.0  0.000000e+00   \n",
      "guest_time         273077.0  0.000000e+00  0.000000e+00    0.0  0.000000e+00   \n",
      "importance         273129.0  3.139921e+02  8.891191e+01  100.0  3.000000e+02   \n",
      "lru                273129.0  4.712480e+00  6.348188e+00    0.0  0.000000e+00   \n",
      "num_threads        273077.0  3.928061e+01  2.682408e+01    2.0  1.700000e+01   \n",
      "otherPrivateDirty  273129.0  1.211232e+04  2.026702e+04    0.0  1.480000e+03   \n",
      "priority           273077.0  1.975093e+01  1.170649e+00    9.0  2.000000e+01   \n",
      "rss                273077.0  8.500590e+03  4.942350e+03    0.0  4.894000e+03   \n",
      "stime              273077.0  1.378527e+03  3.568420e+03    3.0  9.100000e+01   \n",
      "utime              273077.0  2.509427e+03  5.325113e+03    2.0  1.020000e+02   \n",
      "vsize              273077.0  2.049264e+09  1.179834e+08    0.0  1.958326e+09   \n",
      "cminflt                 0.0           NaN           NaN    NaN           NaN   \n",
      "\n",
      "                            50%           75%           max  \n",
      "CPU_USAGE          1.300000e-01  3.700000e-01  1.108900e+02  \n",
      "UidRxBytes         0.000000e+00  0.000000e+00  8.872786e+06  \n",
      "UidRxPackets       0.000000e+00  0.000000e+00  6.165000e+03  \n",
      "UidTxBytes         0.000000e+00  0.000000e+00  9.830372e+06  \n",
      "UidTxPackets       0.000000e+00  0.000000e+00  6.748000e+03  \n",
      "cutime             0.000000e+00  0.000000e+00  1.100000e+01  \n",
      "guest_time         0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "importance         3.000000e+02  4.000000e+02  4.000000e+02  \n",
      "lru                0.000000e+00  1.100000e+01  1.600000e+01  \n",
      "num_threads        3.000000e+01  5.500000e+01  1.410000e+02  \n",
      "otherPrivateDirty  4.308000e+03  1.354800e+04  1.928560e+05  \n",
      "priority           2.000000e+01  2.000000e+01  2.000000e+01  \n",
      "rss                6.959000e+03  1.120600e+04  5.466800e+04  \n",
      "stime              3.450000e+02  1.474000e+03  4.662900e+04  \n",
      "utime              5.650000e+02  2.636000e+03  4.284500e+04  \n",
      "vsize              2.026893e+09  2.125877e+09  2.456613e+09  \n",
      "cminflt                     NaN           NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Load the 18-apps dataset\n",
    "df = pd.read_csv(\"../sherlock/sherlock_18apps.csv\", index_col=0)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique applications: 18\n",
      "\n",
      "Application Frequencies:\n",
      "ApplicationName\n",
      "Google App          60001\n",
      "Chrome              28046\n",
      "Facebook            20103\n",
      "Geo News            19991\n",
      "Messenger           19989\n",
      "WhatsApp            19985\n",
      "Photos              17382\n",
      "ES File Explorer    16667\n",
      "Gmail               16417\n",
      "Calendar             8996\n",
      "Moovit               8365\n",
      "Waze                 8237\n",
      "Hangouts             7608\n",
      "YouTube              5173\n",
      "Maps                 5159\n",
      "Skype                4877\n",
      "Moriarty             3616\n",
      "Messages             2517\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total records: 273129\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Explore application distribution\n",
    "app_frequencies = df['ApplicationName'].value_counts()\n",
    "print(f\"Number of unique applications: {len(app_frequencies)}\")\n",
    "print(f\"\\nApplication Frequencies:\")\n",
    "print(app_frequencies)\n",
    "print(f\"\\nTotal records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with >50.0% missing values: ['cminflt']\n",
      "\n",
      "After cleaning - Shape: (273077, 18)\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Data cleaning and preprocessing\n",
    "df2 = df.copy()\n",
    "\n",
    "# Remove irrelevant columns\n",
    "df2 = df2.drop(['Unnamed: 0'], axis=1, errors='ignore')\n",
    "\n",
    "# Drop columns with too many missing values (>50% missing)\n",
    "missing_threshold = 0.5\n",
    "missing_percent = df2.isna().sum() / len(df2)\n",
    "cols_to_drop = missing_percent[missing_percent > missing_threshold].index.tolist()\n",
    "\n",
    "print(f\"Columns with >{missing_threshold*100}% missing values: {cols_to_drop}\")\n",
    "df2 = df2.drop(columns=cols_to_drop)\n",
    "\n",
    "# Remove rows with remaining missing values\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "print(f\"\\nAfter cleaning - Shape: {df2.shape}\")\n",
    "print(f\"Missing values: {df2.isna().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (273077, 17)\n",
      "Labels shape: (273077,)\n",
      "\n",
      "Feature columns: ['CPU_USAGE', 'UidRxBytes', 'UidRxPackets', 'UidTxBytes', 'UidTxPackets', 'cutime', 'guest_time', 'importance', 'lru', 'num_threads', 'otherPrivateDirty', 'priority', 'rss', 'state', 'stime', 'utime', 'vsize']\n",
      "\n",
      "Data types:\n",
      "CPU_USAGE            float64\n",
      "UidRxBytes             int64\n",
      "UidRxPackets           int64\n",
      "UidTxBytes             int64\n",
      "UidTxPackets           int64\n",
      "cutime               float64\n",
      "guest_time           float64\n",
      "importance             int64\n",
      "lru                    int64\n",
      "num_threads          float64\n",
      "otherPrivateDirty      int64\n",
      "priority             float64\n",
      "rss                  float64\n",
      "state                 object\n",
      "stime                float64\n",
      "utime                float64\n",
      "vsize                float64\n",
      "dtype: object\n",
      "\n",
      "Non-numeric columns: ['state']\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Separate labels from features\n",
    "labels = df2['ApplicationName']\n",
    "df_features = df2.drop('ApplicationName', axis=1)\n",
    "\n",
    "print(f\"Features shape: {df_features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"\\nFeature columns: {df_features.columns.tolist()}\")\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\nData types:\")\n",
    "print(df_features.dtypes)\n",
    "print(f\"\\nNon-numeric columns: {df_features.select_dtypes(exclude=[np.number]).columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: 16 columns\n",
      "Categorical features: 1 columns\n",
      "Categorical columns: ['state']\n",
      "\n",
      "Features normalized successfully!\n",
      "Combined features shape: (273077, 17)\n",
      "\n",
      "Normalized features statistics:\n",
      "          CPU_USAGE    UidRxBytes  UidRxPackets    UidTxBytes  UidTxPackets  \\\n",
      "count  2.730770e+05  2.730770e+05  2.730770e+05  2.730770e+05  2.730770e+05   \n",
      "mean  -6.661086e-18 -8.326358e-19 -2.081589e-19 -2.497907e-18 -1.040795e-18   \n",
      "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
      "min   -2.063179e-01 -1.820392e-02 -4.092106e-01 -1.026034e-02 -5.732477e-02   \n",
      "25%   -1.907310e-01 -1.062313e-02 -1.506781e-02 -8.245287e-03 -1.602201e-02   \n",
      "50%   -1.657920e-01 -1.062313e-02 -1.506781e-02 -8.245287e-03 -1.602201e-02   \n",
      "75%   -9.097502e-02 -1.062313e-02 -1.506781e-02 -8.245287e-03 -1.602201e-02   \n",
      "max    3.436225e+01  2.402136e+02  2.208840e+02  3.301378e+02  2.786950e+02   \n",
      "\n",
      "             cutime  guest_time    importance           lru   num_threads  \\\n",
      "count  2.730770e+05    273077.0  2.730770e+05  2.730770e+05  2.730770e+05   \n",
      "mean   3.996652e-17         0.0 -3.064100e-16 -1.998326e-17  4.621128e-17   \n",
      "std    1.000002e+00         0.0  1.000002e+00  1.000002e+00  1.000002e+00   \n",
      "min   -1.854607e-01         0.0 -2.406593e+00 -7.421499e-01 -1.389821e+00   \n",
      "25%   -1.854607e-01         0.0 -1.571890e-01 -7.421499e-01 -8.306214e-01   \n",
      "50%   -1.854607e-01         0.0 -1.571890e-01 -7.421499e-01 -3.459813e-01   \n",
      "75%   -1.854607e-01         0.0  9.675130e-01  9.908955e-01  5.860188e-01   \n",
      "max    6.034552e+00         0.0  9.675130e-01  1.778643e+00  3.792099e+00   \n",
      "\n",
      "       otherPrivateDirty      priority           rss         stime  \\\n",
      "count       2.730770e+05  2.730770e+05  2.730770e+05  2.730770e+05   \n",
      "mean        2.331380e-17 -1.378845e-15 -6.661086e-17  6.661086e-18   \n",
      "std         1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
      "min        -5.977145e-01 -9.183752e+00 -1.719952e+00 -3.854730e-01   \n",
      "25%        -5.246938e-01  2.127618e-01 -7.297332e-01 -3.608122e-01   \n",
      "50%        -3.851651e-01  2.127618e-01 -3.119150e-01 -2.896321e-01   \n",
      "75%         7.072073e-02  2.127618e-01  5.473943e-01  2.675500e-02   \n",
      "max         8.917472e+00  2.127618e-01  9.341202e+00  1.268084e+01   \n",
      "\n",
      "               utime         vsize  \n",
      "count  273077.000000  2.730770e+05  \n",
      "mean        0.000000  8.992466e-17  \n",
      "std         1.000002  1.000002e+00  \n",
      "min        -0.470869 -1.736912e+01  \n",
      "25%        -0.452090 -7.707703e-01  \n",
      "50%        -0.365144 -1.896108e-01  \n",
      "75%         0.023769  6.493559e-01  \n",
      "max         7.574608  3.452600e+00  \n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Feature scaling\n",
    "# Separate numeric and categorical features\n",
    "numeric_features = df_features.select_dtypes(include=[np.number])\n",
    "categorical_features = df_features.select_dtypes(exclude=[np.number])\n",
    "\n",
    "print(f\"Numeric features: {numeric_features.shape[1]} columns\")\n",
    "print(f\"Categorical features: {categorical_features.shape[1]} columns\")\n",
    "if categorical_features.shape[1] > 0:\n",
    "    print(f\"Categorical columns: {categorical_features.columns.tolist()}\")\n",
    "\n",
    "# Scale only numeric features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(numeric_features)\n",
    "numeric_features_n = pd.DataFrame(scaler.transform(numeric_features),\n",
    "                                   columns=numeric_features.columns,\n",
    "                                   index=numeric_features.index)\n",
    "\n",
    "# Combine scaled numeric features with categorical features\n",
    "if categorical_features.shape[1] > 0:\n",
    "    df_features_n = pd.concat([numeric_features_n, categorical_features], axis=1)\n",
    "else:\n",
    "    df_features_n = numeric_features_n\n",
    "\n",
    "print(\"\\nFeatures normalized successfully!\")\n",
    "print(f\"Combined features shape: {df_features_n.shape}\")\n",
    "print(f\"\\nNormalized features statistics:\")\n",
    "print(df_features_n.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded labels shape: (273077, 18)\n",
      "\n",
      "First 5 rows of one-hot encoded labels:\n",
      "    Calendar  Chrome  ES File Explorer  Facebook  Geo News  Gmail  Google App  \\\n",
      "0      False   False             False     False     False   True       False   \n",
      "6      False   False             False     False     False  False       False   \n",
      "11     False   False             False     False     False  False       False   \n",
      "18     False   False             False     False      True  False       False   \n",
      "19     False   False             False      True     False  False       False   \n",
      "\n",
      "    Hangouts   Maps  Messages  Messenger  Moovit  Moriarty  Photos  Skype  \\\n",
      "0      False  False     False      False   False     False   False  False   \n",
      "6       True  False     False      False   False     False   False  False   \n",
      "11     False  False     False       True   False     False   False  False   \n",
      "18     False  False     False      False   False     False   False  False   \n",
      "19     False  False     False      False   False     False   False  False   \n",
      "\n",
      "     Waze  WhatsApp  YouTube  \n",
      "0   False     False    False  \n",
      "6   False     False    False  \n",
      "11  False     False    False  \n",
      "18  False     False    False  \n",
      "19  False     False    False  \n",
      "\n",
      "Number of classes: 18\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: One-hot encoding for labels\n",
    "df_labels_onehot = pd.get_dummies(labels)\n",
    "\n",
    "print(f\"One-hot encoded labels shape: {df_labels_onehot.shape}\")\n",
    "print(f\"\\nFirst 5 rows of one-hot encoded labels:\")\n",
    "print(df_labels_onehot.head())\n",
    "print(f\"\\nNumber of classes: {df_labels_onehot.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after one-hot encoding: (273077, 20)\n",
      "\n",
      "Feature columns: ['CPU_USAGE', 'UidRxBytes', 'UidRxPackets', 'UidTxBytes', 'UidTxPackets', 'cutime', 'guest_time', 'importance', 'lru', 'num_threads']...\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: One-hot encoding for categorical features\n",
    "df_features_encoded = pd.get_dummies(df_features_n)\n",
    "\n",
    "print(f\"Features after one-hot encoding: {df_features_encoded.shape}\")\n",
    "print(f\"\\nFeature columns: {df_features_encoded.columns.tolist()[:10]}...\")  # Show first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (218461, 20)\n",
      "Test set: (54616, 20)\n",
      "\n",
      "Number of features: 20\n",
      "Number of classes: 18\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Train-test split\n",
    "train_F, test_F, train_L, test_L = train_test_split(\n",
    "    df_features_encoded, df_labels_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {train_F.shape}\")\n",
    "print(f\"Test set: {test_F.shape}\")\n",
    "print(f\"\\nNumber of features: {train_F.shape[1]}\")\n",
    "print(f\"Number of classes: {train_L.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function NN_multiclass_clf created successfully!\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Define a multi-layer neural network for multi-class classification\n",
    "def NN_multiclass_clf(learning_rate=0.001, hidden_units=128):\n",
    "    \"\"\"\n",
    "    Create a multi-layer neural network for multi-class classification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    learning_rate : float\n",
    "        Learning rate for Adam optimizer\n",
    "    hidden_units : int\n",
    "        Number of units in hidden layers\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : Sequential\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, activation='relu', input_shape=(train_F.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(train_L.shape[1], activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    adam = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Function NN_multiclass_clf created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Architecture:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fiery/anaconda3/envs/cb-test-env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">594</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m594\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,618</span> (53.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,618\u001b[0m (53.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,618</span> (53.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,618\u001b[0m (53.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Create and display model architecture\n",
    "model_nn = NN_multiclass_clf(learning_rate=0.001, hidden_units=128)\n",
    "\n",
    "print(\"\\nNeural Network Architecture:\")\n",
    "print(\"=\"*60)\n",
    "model_nn.summary()\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the neural network...\n",
      "============================================================\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Train the neural network\n",
    "print(\"Training the neural network...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history_nn = model_nn.fit(\n",
    "    train_F, train_L,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=(test_F, test_L),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history_nn.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history_nn.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Model Loss', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history_nn.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[1].plot(history_nn.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Model Accuracy', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Training Accuracy: {history_nn.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history_nn.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Evaluate neural network\n",
    "test_loss, test_accuracy = model_nn.evaluate(test_F, test_L, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEURAL NETWORK EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Target Accuracy: >99%\")\n",
    "print(f\"Status: {'✓ ACHIEVED' if test_accuracy > 0.99 else '✗ NOT YET'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with Traditional ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Decision Tree\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DECISION TREE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_dtc = DecisionTreeClassifier(max_depth=15, random_state=42)\n",
    "model_dtc.fit(train_F, train_L.idxmax(axis=1))  # Convert one-hot back to labels\n",
    "\n",
    "test_L_labels = test_L.idxmax(axis=1)\n",
    "test_pred_dtc = model_dtc.predict(test_F)\n",
    "acc_dtc = accuracy_score(test_L_labels, test_pred_dtc)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {acc_dtc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Logistic Regression\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOGISTIC REGRESSION MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_lr.fit(train_F, train_L.idxmax(axis=1))\n",
    "\n",
    "test_pred_lr = model_lr.predict(test_F)\n",
    "acc_lr = accuracy_score(test_L_labels, test_pred_lr)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {acc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Neural Network', 'Decision Tree', 'Logistic Regression'],\n",
    "    'Test Accuracy': [test_accuracy, acc_dtc, acc_lr]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_idx = comparison_df['Test Accuracy'].idxmax()\n",
    "print(f\"\\nBest Model: {comparison_df.loc[best_idx, 'Model']}\")\n",
    "print(f\"Best Accuracy: {comparison_df.loc[best_idx, 'Test Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "models = comparison_df['Model']\n",
    "accuracies = comparison_df['Test Accuracy']\n",
    "colors = ['steelblue', 'coral', 'lightgreen']\n",
    "\n",
    "bars = ax.bar(models, accuracies, color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "ax.set_title('Multi-Class Classification: Model Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.axhline(y=0.99, color='red', linestyle='--', linewidth=2, label='Target (99%)')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings and Discussion\n",
    "\n",
    "### Observations:\n",
    "\n",
    "1. **Multi-Class Challenge**: Classifying 18 apps is significantly more challenging than binary classification\n",
    "\n",
    "2. **Neural Network Advantages**:\n",
    "   - Can learn complex non-linear relationships\n",
    "   - Better performance on high-dimensional data\n",
    "   - Flexible architecture for different problem complexities\n",
    "\n",
    "3. **One-Hot Encoding**: Essential for multi-class classification with neural networks\n",
    "\n",
    "4. **Dropout Regularization**: Helps prevent overfitting in deep networks\n",
    "\n",
    "### Why Neural Networks Excel:\n",
    "\n",
    "- **Hidden Layers**: Enable learning of hierarchical features\n",
    "- **Non-linear Activations**: ReLU captures complex patterns\n",
    "- **Softmax Output**: Proper probability distribution for multi-class\n",
    "- **Categorical Crossentropy**: Appropriate loss for multi-class problems\n",
    "\n",
    "### Achieving >99% Accuracy:\n",
    "\n",
    "To reach the target accuracy:\n",
    "1. Increase model capacity (more hidden units)\n",
    "2. Train for more epochs\n",
    "3. Adjust learning rate\n",
    "4. Use data augmentation\n",
    "5. Ensemble multiple models\n",
    "\n",
    "### Cybersecurity Applications:\n",
    "\n",
    "- **App Classification**: Identify running applications on mobile devices\n",
    "- **Malware Detection**: Classify apps as benign or malicious\n",
    "- **Behavioral Analysis**: Detect anomalous application behavior\n",
    "- **Threat Intelligence**: Build profiles of known malicious applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb-test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
