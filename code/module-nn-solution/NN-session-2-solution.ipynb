{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN-Session-2 Solution: Multi-Class Classification with Keras\n",
    "\n",
    "This notebook provides complete solutions for the NN-session-2 exercises.\n",
    "It demonstrates how to build neural networks for multi-class classification using Keras on the 18-apps dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading and Exploring the 18-Apps Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Load the 18-apps dataset\ndf = pd.read_csv(\"sherlock/sherlock_18apps.csv\", index_col=0)\n\nprint(\"Dataset Shape:\", df.shape)\nprint(\"\\nFirst few rows:\")\nprint(df.head())\nprint(\"\\nDataset Info:\")\ndf.info()\nprint(\"\\nBasic Statistics:\")\nprint(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Explore application distribution\napp_frequencies = df['ApplicationName'].value_counts()\nprint(f\"Number of unique applications: {len(app_frequencies)}\")\nprint(f\"\\nApplication Frequencies:\")\nprint(app_frequencies)\nprint(f\"\\nTotal records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Data cleaning and preprocessing\ndf2 = df.copy()\n\n# Remove irrelevant columns\ndf2 = df2.drop(['Unnamed: 0'], axis=1, errors='ignore')\n\n# Remove rows with missing values\ndf2.dropna(inplace=True)\n\nprint(f\"After cleaning - Shape: {df2.shape}\")\nprint(f\"Missing values: {df2.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Separate labels from features\nlabels = df2['ApplicationName']\ndf_features = df2.drop('ApplicationName', axis=1)\n\nprint(f\"Features shape: {df_features.shape}\")\nprint(f\"Labels shape: {labels.shape}\")\nprint(f\"\\nFeature columns: {df_features.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Feature scaling\nscaler = preprocessing.StandardScaler()\nscaler.fit(df_features)\ndf_features_n = pd.DataFrame(scaler.transform(df_features),\n                             columns=df_features.columns,\n                             index=df_features.index)\n\nprint(\"Features normalized successfully!\")\nprint(f\"\\nNormalized features statistics:\")\nprint(df_features_n.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: One-hot encoding for labels\ndf_labels_onehot = pd.get_dummies(labels)\n\nprint(f\"One-hot encoded labels shape: {df_labels_onehot.shape}\")\nprint(f\"\\nFirst 5 rows of one-hot encoded labels:\")\nprint(df_labels_onehot.head())\nprint(f\"\\nNumber of classes: {df_labels_onehot.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: One-hot encoding for categorical features\ndf_features_encoded = pd.get_dummies(df_features_n)\n\nprint(f\"Features after one-hot encoding: {df_features_encoded.shape}\")\nprint(f\"\\nFeature columns: {df_features_encoded.columns.tolist()[:10]}...\")  # Show first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train-test split\ntrain_F, test_F, train_L, test_L = train_test_split(\n    df_features_encoded, df_labels_onehot, test_size=0.2, random_state=42\n)\n\nprint(f\"Training set: {train_F.shape}\")\nprint(f\"Test set: {test_F.shape}\")\nprint(f\"\\nNumber of features: {train_F.shape[1]}\")\nprint(f\"Number of classes: {train_L.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Define a multi-layer neural network for multi-class classification\ndef NN_multiclass_clf(learning_rate=0.001, hidden_units=128):\n",
    "    \"\"\"\n",
    "    Create a multi-layer neural network for multi-class classification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    learning_rate : float\n",
    "        Learning rate for Adam optimizer\n",
    "    hidden_units : int\n",
    "        Number of units in hidden layers\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : Sequential\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, activation='relu', input_shape=(train_F.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(train_L.shape[1], activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    adam = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Function NN_multiclass_clf created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Create and display model architecture\nmodel_nn = NN_multiclass_clf(learning_rate=0.001, hidden_units=128)\n\nprint(\"\\nNeural Network Architecture:\")\nprint(\"=\"*60)\nmodel_nn.summary()\nprint(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train the neural network\nprint(\"Training the neural network...\")\nprint(\"=\"*60)\n\nhistory_nn = model_nn.fit(\n    train_F, train_L,\n    epochs=50, batch_size=32,\n    validation_data=(test_F, test_L),\n    verbose=1\n)\n\nprint(\"=\"*60)\nprint(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Plot training history\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].plot(history_nn.history['loss'], label='Training Loss', linewidth=2)\naxes[0].plot(history_nn.history['val_loss'], label='Validation Loss', linewidth=2)\naxes[0].set_xlabel('Epoch', fontsize=12)\naxes[0].set_ylabel('Loss', fontsize=12)\naxes[0].set_title('Model Loss', fontsize=13, fontweight='bold')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(history_nn.history['accuracy'], label='Training Accuracy', linewidth=2)\naxes[1].plot(history_nn.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\naxes[1].set_xlabel('Epoch', fontsize=12)\naxes[1].set_ylabel('Accuracy', fontsize=12)\naxes[1].set_title('Model Accuracy', fontsize=13, fontweight='bold')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Final Training Accuracy: {history_nn.history['accuracy'][-1]:.4f}\")\nprint(f\"Final Validation Accuracy: {history_nn.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Evaluate neural network\ntest_loss, test_accuracy = model_nn.evaluate(test_F, test_L, verbose=0)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"NEURAL NETWORK EVALUATION\")\nprint(\"=\"*60)\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Target Accuracy: >99%\")\nprint(f\"Status: {'✓ ACHIEVED' if test_accuracy > 0.99 else '✗ NOT YET'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with Traditional ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Decision Tree\nprint(\"\\n\" + \"=\"*60)\nprint(\"DECISION TREE MODEL\")\nprint(\"=\"*60)\n\nmodel_dtc = DecisionTreeClassifier(max_depth=15, random_state=42)\nmodel_dtc.fit(train_F, train_L.idxmax(axis=1))  # Convert one-hot back to labels\n\ntest_L_labels = test_L.idxmax(axis=1)\ntest_pred_dtc = model_dtc.predict(test_F)\nacc_dtc = accuracy_score(test_L_labels, test_pred_dtc)\n\nprint(f\"Decision Tree Accuracy: {acc_dtc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Train Logistic Regression\nprint(\"\\n\" + \"=\"*60)\nprint(\"LOGISTIC REGRESSION MODEL\")\nprint(\"=\"*60)\n\nmodel_lr = LogisticRegression(max_iter=1000, random_state=42)\nmodel_lr.fit(train_F, train_L.idxmax(axis=1))\n\ntest_pred_lr = model_lr.predict(test_F)\nacc_lr = accuracy_score(test_L_labels, test_pred_lr)\n\nprint(f\"Logistic Regression Accuracy: {acc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Create comparison table\ncomparison_df = pd.DataFrame({\n",
    "    'Model': ['Neural Network', 'Decision Tree', 'Logistic Regression'],\n",
    "    'Test Accuracy': [test_accuracy, acc_dtc, acc_lr]\n",
    "})\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"MODEL COMPARISON\")\nprint(\"=\"*60)\nprint(comparison_df.to_string(index=False))\nprint(\"=\"*60)\n\nbest_idx = comparison_df['Test Accuracy'].idxmax()\nprint(f\"\\nBest Model: {comparison_df.loc[best_idx, 'Model']}\")\nprint(f\"Best Accuracy: {comparison_df.loc[best_idx, 'Test Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Visualize comparison\nfig, ax = plt.subplots(figsize=(10, 6))\n\nmodels = comparison_df['Model']\naccuracies = comparison_df['Test Accuracy']\ncolors = ['steelblue', 'coral', 'lightgreen']\n\nbars = ax.bar(models, accuracies, color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n\nax.set_ylabel('Test Accuracy', fontsize=12)\nax.set_title('Multi-Class Classification: Model Comparison', fontsize=14, fontweight='bold')\nax.set_ylim([0, 1])\nax.axhline(y=0.99, color='red', linestyle='--', linewidth=2, label='Target (99%)')\nax.grid(axis='y', alpha=0.3)\nax.legend()\n\nfor bar, acc in zip(bars, accuracies):\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height,\n            f'{acc:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n\nplt.xticks(rotation=15, ha='right')\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings and Discussion\n",
    "\n",
    "### Observations:\n",
    "\n",
    "1. **Multi-Class Challenge**: Classifying 18 apps is significantly more challenging than binary classification\n",
    "\n",
    "2. **Neural Network Advantages**:\n",
    "   - Can learn complex non-linear relationships\n",
    "   - Better performance on high-dimensional data\n",
    "   - Flexible architecture for different problem complexities\n",
    "\n",
    "3. **One-Hot Encoding**: Essential for multi-class classification with neural networks\n",
    "\n",
    "4. **Dropout Regularization**: Helps prevent overfitting in deep networks\n",
    "\n",
    "### Why Neural Networks Excel:\n",
    "\n",
    "- **Hidden Layers**: Enable learning of hierarchical features\n",
    "- **Non-linear Activations**: ReLU captures complex patterns\n",
    "- **Softmax Output**: Proper probability distribution for multi-class\n",
    "- **Categorical Crossentropy**: Appropriate loss for multi-class problems\n",
    "\n",
    "### Achieving >99% Accuracy:\n",
    "\n",
    "To reach the target accuracy:\n",
    "1. Increase model capacity (more hidden units)\n",
    "2. Train for more epochs\n",
    "3. Adjust learning rate\n",
    "4. Use data augmentation\n",
    "5. Ensemble multiple models\n",
    "\n",
    "### Cybersecurity Applications:\n",
    "\n",
    "- **App Classification**: Identify running applications on mobile devices\n",
    "- **Malware Detection**: Classify apps as benign or malicious\n",
    "- **Behavioral Analysis**: Detect anomalous application behavior\n",
    "- **Threat Intelligence**: Build profiles of known malicious applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python3",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
