{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeapSECURE module 6: Parallel Programming**\n",
    "\n",
    "# Session 2: Parallelizing a Serial Code with MPI\n",
    "\n",
    "Welcome to the DeapSECURE online training program!\n",
    "This is a Jupyter notebook for the hands-on learning activities of the\n",
    "[\"Parallel and High-Performance Programming\" module](https://deapsecure.gitlab.io/deapsecure-lesson06-par/), pisodes 5: [\"Problem Decomposition\"](https://deapsecure.gitlab.io/deapsecure-lesson06-par/20-problem-decomposition/index.html) and 7: [\"Parallel Computation of Statistics of a Large Array\"](https://deapsecure.gitlab.io/deapsecure-lesson06-par/25-parallel-reduction/index.html).\n",
    "Please visit the [DeapSECURE](https://deapsecure.gitlab.io/) website to learn more about our training program.\n",
    "\n",
    "\n",
    "<a id=\"TOC\"></a>\n",
    "**Quick Links** (sections of this notebook):\n",
    "\n",
    "* 1 [Setup](#sec-Setup)\n",
    "* 2 [Introduction](#sec-Intro)\n",
    "* 3 [Serial Program](#sec-Serial_prog)\n",
    "* 4 [Problem Decomposition in One Dimension](#sec-Problem_decomp)\n",
    "* 5 [Parallel Program](#sec-Par_prog)\n",
    "* 6 [Distributing Data](#sec-Distrib)\n",
    "* 7 [Additional Improvements and Exercises](#sec-Additional_ex)\n",
    "\n",
    "\n",
    "> **CAUTIONS**\n",
    ">\n",
    "> <!-- FIXME FIXME FIXME\n",
    "> In this session, we will use this notebook as partly Python and partly UNIX shell to invoke MPI programs directly from the Jupyter notebook in order to capture the results in the same notebook.\n",
    "> This notebook was designed with ODU Wahab cluster and Open OnDemand in mind, in which it is possible to launch MPI programs within the notebook environment.\n",
    "> Sufficient number of CPU cores must be requested when starting this Jupyter session to run MPI programs interactively from the notebook.\n",
    "> Otherwise, the program must be invoked through your cluster's job scheduler.\n",
    "> -->\n",
    ">\n",
    "> **FOR THE TIME BEING, DO NOT LAUNCH MPI JOBS FROM THIS NOTEBOOK.**\n",
    ">\n",
    "> The trick to launch MPI programs from within a notebook is still broken and still canoot be done.\n",
    "> Please launch MPI jobs directly from the login node's terminal using an appropriate job script and the `sbatch` command, not from Jupyter terminal.\n",
    "> Please follow your instructor regarding the specific way of running MPI programs on your HPC site.\n",
    ">\n",
    "> There is a lot of variabilities regarding how one must run MPI programs on a particular HPC site, as well as the timing results of the MPI programs.\n",
    "> Running the programs on different clusters will definitely result in different timing as well.\n",
    "> For this reason, this notebook is not intended to be strictly reproducible across different environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Setup\"></a>\n",
    "## 1. Setup Instructions\n",
    "\n",
    "If you are opening this notebook from Wahab cluster's OnDemand interface, you're all set.\n",
    "\n",
    "If you see this notebook elsewhere and want to perform the exercises on Wahab cluster, please follow the steps outlined in our setup procedure.\n",
    "\n",
    "1. Make sure you have activated your HPC service.\n",
    "2. Point your web browser to https://ondemand.wahab.hpc.odu.edu/ and sign in with your MIDAS ID and password.\n",
    "3. Create a new Jupyter session with the following parameters: Python version **3.7**, Python suite `tensorflow 2.6 + pytorch 1.10`, Number of Cores **1**, Number of GPU **0**, Partition `main`, and Number of Hours at least **4**. (See <a href=\"https://wiki.hpc.odu.edu/en/ood-jupyter\" target=\"_blank\">ODU HPC wiki</a> for more detailed help.)\n",
    "\n",
    "4. Get the necessary files using commands below within Jupyter:\n",
    "\n",
    "       mkdir -p ~/CItraining/module-par\n",
    "       cp -pr /shared/DeapSECURE/module-par/. ~/CItraining/module-par\n",
    "\n",
    "Using the file manager on the left sidebar, now change the working directory to `~/CItraining/module-par`.\n",
    "The file name of this notebook is `Par-session-2-Reduction.ipynb`.\n",
    "\n",
    "<!--\n",
    "> **VERY IMPORTANT:** Make sure that you start the Jupyter session with at least **4 cores**. We will use this notebook to launch real MPI programs, so multiple CPU cores are needed.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reminder\n",
    "\n",
    "* Throughout this notebook, `#TODO` is used as a placeholder where you need to fill in with something appropriate. \n",
    "* To run a code in a cell, press `Shift+Enter`.\n",
    "* Use `ls` to view the contents of a directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Loading Python Libraries\n",
    "\n",
    "<!--\n",
    "Now we need to **import** the required libraries into this Jupyter notebook:`numpy`.\n",
    "-->\n",
    "\n",
    "<!--\n",
    "**Important**: On Wahab HPC, software packages, including Python libraries, are managed and deployed via *environment modules*.\n",
    "Before we can import the Python libraries in our current notebook, we have to load the corresponding environment modules.\n",
    "We have setup a custom environment \"DeapSECURE\" which will load all the required libraries for this workshop. Please load \"DeapSECURE\" module.\n",
    "\n",
    "* Load the modules above using the `module(\"load\", \"MODULE\")` or `module(\"load\", \"MODULE1\", \"MODULE2\", \"MODULE n\")` statement.\n",
    "* Next, invoke `module(\"list\")` to confirm that these modules are loaded.\n",
    "* In this module, we have setup a custom environment \"DeapSECURE\" including all the required libraries. Please load \"DeapSECURE\" module. (You can also setup your [custom environment](https://wiki.hpc.odu.edu/Software/Python#install-additional-python-modules))\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the following standard Python libraries:\n",
    "`os`, `re`, `sys`, `numpy`, `time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment, edit, and run code below to import libraries\"\"\";\n",
    "#import #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the functions from DeapSECURE's special module, `parallel_prog_env`, to make MPI programs available & invocable from your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment and run these commands\"\"\";\n",
    "\n",
    "#import parallel_prog_env\n",
    "#from parallel_prog_env import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes MPI-related programs and modules available to this notebook:\n",
    "load_parallel_prog_env(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**: `parallel_prog_env` is a DeapSECURE-specific module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Shell Commands inside the Jupyter Notebook\n",
    "\n",
    "Lines that start with `!`are passed directly to the system shell. For example, `!ls` will run `ls`in the current directory.\n",
    "\n",
    "Find out the following:\n",
    "\n",
    "* Use the `hostname` to print the name of the compute node you're running in.\n",
    "* Use the `date` command to print the present date/time.\n",
    "* Use the `pwd` command to print your current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Intro\"></a>\n",
    "## 2. Introduction\n",
    "\n",
    "Parallel programming is a challenging task.\n",
    "For this reason, we provide several options for learners to take according to what's comfortable to them.\n",
    "\n",
    "1) **Option 1 (easy)**: see the example of (almost) the parallelized code and understand the effects of parallelization.\n",
    "   There will be opportunities to exercise some MPI programming by improving the code.\n",
    "\n",
    "2) **Option 2 (challenging)**: perform parallelization from scratch, based on the serial code and the skeleton of `master_template.py`.\n",
    "   This requires a strong programming skill and willingness to troubleshoot the code.\n",
    "\n",
    "\n",
    "In this workshop, we provide two Python programs to parallelize:\n",
    "\n",
    "1. `rand_reduction_seq.py` -- a program which generates many random numbers and compute the average and standard deviation. Let's give a nickname for this computational problem: \"**rand_reduction**\".\n",
    "\n",
    "2. `encrypt_img.py` -- a program which reads an image file and encrypts it pixel-by-pixel, and saves the encrypted image in a JSON format. Let's name this computational problem \"**encrypt_img**\".\n",
    "\n",
    "**CHALLENGE**: This notebook is focused on the parallelization of the first program, **rand_reduction**.\n",
    "Those who are interested in a challenge and find the first program too trivial can go straight to the **encrypt_img** program and attempt to parallelize it from scratch.\n",
    "Make sure you follow the steps prescribed below, though, as they are (mostly) independent of the program being parallelized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Serial_prog\"></a>\n",
    "## 3. The Serial Program: `rand_reduction_seq.py`\n",
    "\n",
    "The first step in parallelizing any program is to become familiar with the original (serial) program and obtain the performance characteristics of the program.\n",
    "The `rand_reduction_seq.py` program is located in the `reduction` subdirectory.\n",
    "\n",
    "If you have not already done so, please issue: `cd reduction` once. Check if you have the `rand_reduction_seq.py` file in your new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Objective of Computation\n",
    "\n",
    "The **rand_reduction** program generates many random numbers $\\{ n_0, n_1, ... n_{N-1} \\}$ (where $N$ = 10 million by default; this can be adjusted) and save them in the array called `NUMBERS`.\n",
    "(Important: The program must be general enough because we must be able to replace the random numbers with a different stream of (non-random) numbers later on.)\n",
    "\n",
    "The goal of the program is to compute the average and standard deviation of these numbers.\n",
    "To do so, we must compute two sums:\n",
    "\n",
    "$$P \\equiv n_0 + n_1 + ... + n_{N-1} \\equiv \\sum_i n_i$$\n",
    "\n",
    "$$Q \\equiv n_0^2 + n_1^2 + ... + n_{N-1}^2 \\equiv \\sum_i n_i^2$$\n",
    "\n",
    "\n",
    "The average is given by:\n",
    "\n",
    "$$\\langle n \\rangle = P/N$$\n",
    "\n",
    "and the standard deviation is given by\n",
    "\n",
    "$$\\sigma = \\sqrt{ Q/N - (P/N)^2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Running the Serial Program\n",
    "\n",
    "**EXERCISE:** Run the `rand_reduction_seq.py` program and get the timing information!\n",
    "\n",
    "* There are no input files required. \n",
    "* Extra bonus: Create a job script for the program and run it through the SLURM job scheduler.\n",
    "* Observe how much time is required to complete the calculation. The program reports this time at the end.\n",
    "\n",
    "*HINT:* The program can be run in UNIX shell or in this Jupyter notebook. Recall that `!` allows shell commands to be run in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*>> (edit this cell to record your answer & observation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### BONUS EXERCISE: Job Script\n",
    ">\n",
    "> A job script can be created to run the program through the job scheduler.\n",
    "> This is *the* recommended way to run jobs on HPC (especially the long-running jobs).\n",
    "> This script becomes essential when the program is converted to parallel.\n",
    ">\n",
    "> ```bash\n",
    "> #!/bin/bash\n",
    "> #SBATCH --job-name=rand_reduction_seq\n",
    "> #SBATCH --ntasks=1\n",
    "> #SBATCH --output=rand_reduction_seq.out\n",
    "> #SBATCH --time=1:00:00\n",
    ">\n",
    "> source parallel-prog-env\n",
    "> python3 rand_reduction_seq.py\n",
    "> ```\n",
    ">\n",
    "> *Notes*:\n",
    ">\n",
    "> * The job script above is for running the serial program.\n",
    "> * The `--ntasks` flag determines the number of processes (UNIX tasks), which is obviously one for a serial program.\n",
    "> * The `source parallel-prog-env` reads additional commands from `parallel-prog-env`, which loads the necessary environment modules for `mpiexec`, `python3` and other tools needed later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Analyzing the Serial Program and Identifying the Parts\n",
    "\n",
    "**EXERCISE:**\n",
    "Open the program in a text editor or viewer and identify the steps of the program.\n",
    "Since this is a purely serial program, the parts that you need to identify will only be\n",
    "  \n",
    "  - `PROCESS_INPUT_DATA`\n",
    "  - `DO_WORK`\n",
    "  - `FINALIZE_AND_REPORT_RESULTS`\n",
    "  \n",
    "*(You are encouraged to work on this exercise with your breakout group!)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*>> (edit this cell to record your answer & observation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Finding the Execution Hotspot\n",
    "\n",
    "The goal of parallel programming is to *significantly* shorten the program's execution time.\n",
    "Usually, a few parts of the program would account a large fraction of the execution time.\n",
    "This means that the very first thing to do is to find which part(s) of the code are taking a lot of time.\n",
    "For this exercise, we will employ a very simple time measurement, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# ... some prior codes here\n",
    "\n",
    "t1 = time.time()\n",
    "# Replace the sleep() below with the real code line(s), whose execution time will be measured\n",
    "time.sleep(0.05)\n",
    "t2 = time.time()\n",
    "print('timing: <DESCRIBE_CODE_PART>: ', t2 - t1, 'secs')\n",
    "\n",
    "# ... more codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet above measures and prints the execution time, defined by `t2 - t1`, of the code line(s) in between the two time measurements.\n",
    "In the example above we only measure a single \"sleep\" command.\n",
    "In real codes, you may measure a loop, or a few lines, or a few blocks of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be more than one time measurement in a given code.\n",
    "Many good codes record and print the time measurement of their major computations/actions.\n",
    "\n",
    "*HINTS:* Quite frequently, execution hot spots involve:\n",
    "\n",
    "* Loops with large number of iterations\n",
    "* Computation with lots of data (e.g. large arrays)\n",
    "\n",
    "Additionally, you must also suspect function calls, as we may or may not have knowledge about what's being done there.\n",
    "\n",
    "**EXERCISE 3:**\n",
    "Using the simple timing trick above, find a section of the code that takes a long time to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*>> (edit this cell to record your answer & observation)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(This may take a few trials-and-errors to find out. Don't give up!)*\n",
    "\n",
    "Now that you have identified the expensive part(s) of the program, you will want to device a strategy to parallelize that part(s).\n",
    "\n",
    "> ### Profiling the Code\n",
    ">\n",
    "> Timing sections of a code as done in the previous exercise is not always practical.\n",
    "> Unless you are familiar with the computational methodology and have a good sense of where to measure, it will be a lot of trial and error to find the expensive section of the code!\n",
    "> There is a tool called \"profiler\" which will help you pinpoint the lines of code, or the function calls, which take a lot of time to execute.\n",
    ">\n",
    "> Python has a package called `line_profiler` which can measure the amount of time spent in a function, line-by-line.\n",
    "> There is a good lesson for this which you can follow: <http://www.hpc-carpentry.org/hpc-parallel-novice/01-estimate-of-pi/index.html> .\n",
    "> If you have a real application to speed up (whether to parallelize or not), this is definitely the first step you will want to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Problem_decomp\"></a>\n",
    "## 4. Problem Decomposition in One Dimension\n",
    "\n",
    "In order to do so, we must first break up the expensive computation into parts that can be executed in parallel.\n",
    "This effort of \"breaking-up\" tasks into smaller pieces is often referred to as ***problem decomposition*** or ***domain decomposition***.\n",
    "\n",
    "A very common scenario in problem-decomposition is the distribution of $N$ independent tasks as evenly as possible among $P$ workers.\n",
    "(This is to say that there is no interdependence among these tasks that would yield invalid results when executed in parallel.)\n",
    "\n",
    "![Decomposition of array N=12 P=4](images/domainDecomp-1D-array_N12_P4.png)\n",
    "\n",
    "The illustration above shows the distribution of $N=12$ numbers into $P=4$ partitions, where each partition corresponds to a worker.\n",
    "This approach works well to minimize the processing time if each task takes the same amount of time to process.\n",
    "\n",
    "<!--\n",
    "Suppose we have N items that have to be split as evenly as possible across P partitions.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* N=10 million elements to be processed by P=4 workers\n",
    "* N=100 rows to be processed by P=7 workers\n",
    "\n",
    "-->\n",
    "\n",
    "**EXERCISE**: create a subprogram to divide up the $N$ items as evenly as possible among the workers?\n",
    "Per MPI convention, we will label the workers with $r = 0, 1, ... (P-1)$.\n",
    "\n",
    "### 4.1 Cases to Test\n",
    "\n",
    "Here are some cases against which to test the correctness of your subprogram (or function):\n",
    "\n",
    "1. $N$ being an integer multiples of $P$.\n",
    "   Examples:\n",
    "\n",
    "   * $N = 12; P = 4$\n",
    "   * $N = 100; P = 4$\n",
    "   * $N = 72; P = 8$\n",
    "\n",
    "   \n",
    "2. $N$ not being an integer multiples of $P$.\n",
    "   Examples:\n",
    "\n",
    "   * $N = 14; P = 4$\n",
    "   * $N = 100; P = 7$\n",
    "\n",
    "\n",
    "3. $N < P$ (corner case, but not uncommon).\n",
    "   Example: $N = 5; P = 7$\n",
    "\n",
    "\n",
    "4. $N == 0; P > 0$.\n",
    "   Example: $N = 0; P = 7$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Manual Solution Workout\n",
    "\n",
    "We will first try to solve this manually, then derive a formula (i.e. a Python expression) that can be evaluated by the computer.\n",
    "\n",
    "#### Easy Case: $N$ divisible by $P$\n",
    "\n",
    "Consider a concrete example of $N=12, P=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12\n",
    "P = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many items does each worker receive (call this `worksize`)? Express it also in terms of `N` and `P` (i.e. as a mathematical formula involving $N$ and $P$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the *inclusive* lower (`L`) and *exclusive* upper (`U`) bounds of the original array received by worker with rank `r`? We follow the convention of Python for upper bound: where the elements assigned to a worker `r` will be `NUMBERS[L]`, `NUMBERS[L+1]`, ... `NUMBERS[U-1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(your answer here)*\n",
    "\n",
    "- for rank 0: L=... U=...\n",
    "- for rank 1: L=... U=...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by definition, `worksize = U - L`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Based on the manually worked-out `L`'s and `U`'s above, create the appropriate formulas for them involving `N`, `P`, and `r`.\n",
    "\n",
    "*Hints*: you can use the integer division operator `//` or the `int()` function to yield integers instead of real numbers.\n",
    "The `L` and `U` variables should be an array with `r` as its index, as each worker is supposed to have a non-overlapping range of tasks (or data elements) to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(your answer here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test your formula for various `r`'s for the same `N` and `P`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use as many python cells as you need here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Hint*: It pays well to write a loop and/or a function to expedite the testings below.\n",
    "> For example, you can use this as a starting point:\n",
    ">\n",
    "> ```python\n",
    "> L = [0] * N\n",
    "> U = [0] * N\n",
    "> for r in range(N):\n",
    ">     L[r] = ...\n",
    ">     U[r] = ...\n",
    "> ```\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> *Advanced Hint*: If you know NumPy, you can replace `[0] * N` with `numpy.zeros((N,), dtype=int)` for a more robust array, and use NumPy's array operations to get rid of the `for` loop altogether!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalizing the Formula\n",
    "\n",
    "It is important to test that your formula works correctly on general cases.\n",
    "Test your formula for various combinations of `N` and `P`, trying out several `r` values as well.\n",
    "At minimum, test it against:\n",
    "\n",
    "* $N=14, P=4$  (N not divisible by P)\n",
    "* $N=5, P=7$   (N < P)\n",
    "\n",
    "**Important**:\n",
    "You must make sure that all the `N` elements will be distributed into the partitions, and no element is assigned multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HINTS**: *Possible* correct solution tables are given below.\n",
    "\n",
    "For $N=14, P=4$:\n",
    "\n",
    "```\n",
    "r           L        U  worksize\n",
    "0           0        3         3\n",
    "1           3        7         4\n",
    "2           7       10         3\n",
    "3          10       14         4\n",
    "```\n",
    "\n",
    "For $N=5, P=7$:\n",
    "\n",
    "```\n",
    "r           L        U  worksize\n",
    "0           0        0         0\n",
    "1           0        1         1\n",
    "2           1        2         1\n",
    "3           2        2         0\n",
    "4           2        3         1\n",
    "5           3        4         1\n",
    "6           4        5         1\n",
    "```\n",
    "\n",
    "Your solution table may vary depending on the specific algorithm you use.\n",
    "For example, in the first table, your method may return slightly different answer on which rank would get `worksize=3` or `4`.\n",
    "But the sum of all `worksize`'s must equal to $N$, and there must not be any overlap or gap among the $[L, (U-1)]$ intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Optional Exercise**\n",
    "\n",
    "Write a simple Python code here to print a table containing 4 columns: rank, lower bound, upper bound, number of elements.\n",
    "A possible output looks like:\n",
    "\n",
    "```\n",
    "0  0  3  3\n",
    "1  3  7  4\n",
    "2 28 42 14\n",
    "3 42 57 15\n",
    "...\n",
    "```\n",
    "or\n",
    "\n",
    "```\n",
    "(0, 0, 14, 14)\n",
    "(1, 14, 28, 14)\n",
    "(2, 28, 42, 14)\n",
    "(3, 42, 57, 15)\n",
    "...\n",
    "```\n",
    "\n",
    "(The columns may not align, as long as it makes it easy for you to inspect.)\n",
    "\n",
    "*Hints*: Use the `for r in range(P): ...` construct to print the values line-by-line. Advanced users may try using pandas' DataFrame.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above can be very useful for visually inspecting the result of decomposition. \n",
    "\n",
    "(end optional exercise)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Par_prog\"></a>\n",
    "## 5. Parallel Program: Starter's Edition\n",
    "\n",
    "We provide an example of a starter program that is partially parallelized---it still needs some work.\n",
    "The starter parallel program is located at `reduction/rand_reduction_par.py`.\n",
    "\n",
    "For **option 1**, we will guide you to complete this parallelization.\n",
    "If you want to parallelize from scratch, feel free to use this program as a \"cheat sheet\" to see how certain things are done, but be careful of the issue pointed out in section \"**6. Distributing Data**\" below.\n",
    "\n",
    "Regardless if you want to parallelize the program, please go through the following exercises to understand the characteristics of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Running the Parallel Program\n",
    "\n",
    "**EXERCISE**: Run `rand_reduction_par.py` and observe the speedup\n",
    "\n",
    "* Run it with 4 cores\n",
    "* Use `mpiexec python3 SCRIPTNAME.py` to launch the MPI program.\n",
    "* Create a job script for the program and submit it to the job scheduler (`sbatch JOB_SCRIPT`).\n",
    "* Verify if the results of the parallel computation are still the same as the serial computation before, but the timing is reduced\n",
    "\n",
    "Let's name the execution timing with 4 cores: $T_4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*>> (edit this cell to record your answer & observation)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"How to run parallel program interactively from Jupyter:\n",
    "Uncomment the following line and add --oversubscribe flag on Wahab.\"\"\";\n",
    "#! mpiexec   -n 4 python3 #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Parallel Speedup\n",
    "\n",
    "Let's define the *speedup* due to 4-worker parallelism as\n",
    "\n",
    "$$S_4 \\equiv \\frac{T_{serial}}{T_4}$$\n",
    "\n",
    "What is the speedup of this parallel run?\n",
    "\n",
    "Ideally $S_4$ should be 4, but it will not be.\n",
    "The actual speedup divided by the ideal speedup is called the *parallel efficiency*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uncomment and complete the code below with your observed results\"\"\";\n",
    "\n",
    "# T_serial = #TODO    ## What was the timing result from running the serial program?\n",
    "# T_4 = #TODO         ## What was the result from running the parallel program with 4 cores?\n",
    "# S_4 = #TODO         ## How to find the speedup?\n",
    "# print(\"4-worker speedup =\", S_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Parallel Scaling\n",
    "\n",
    "**EXERCISE**: Run the code with different number of workers ($P$):\n",
    "\n",
    "  * 1 core (any difference from the serial run?)\n",
    "  * 2 cores\n",
    "  * 4 cores (the case above)\n",
    "  * 8 cores\n",
    "  * 16 cores\n",
    "\n",
    "Take note of the execution timings in each ($T_1$, $T_2$, ...). Using Matplotlib, plot $T_P$ as a function of $P$ and see the effect of parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Replace numbers with execution timings found above.\n",
    "You may want to consider numpy arrays for versatility.\"\"\";\n",
    "#T = numpy.array([#TODO])\n",
    "#S = T / T_serial\n",
    "#print(\"Timing =\", T)\n",
    "#print(\"Speedup =\", S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code to display your speedup result:\n",
    "\n",
    "```python\n",
    "# This is a simple way to plot the data;\n",
    "# check out the documentation on matplotlib for more ways\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Change the values to plot the Speedup vs. Time\n",
    "Procs = [ 1, 2, 4, 8, 16 ]\n",
    "# WP's results (early 2021 on Wahab w/ legacy Python)\n",
    "Timings = #TODO\n",
    "Speedups = [ Timings[0] / T for T in Timings ]\n",
    "\n",
    "ax.plot(Procs, Speedups)\n",
    "ax.set_xlabel('Timing')\n",
    "ax.set_ylabel('Speedup')\n",
    "ax.set_title('Speedup vs. Timing')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Distrib\"></a>\n",
    "## 6. Distributing Data\n",
    "\n",
    "The starter parallel program can get reasonable speedup by running it with multiple workers, but there is one **fundamental problem**: the working data (`NUMBERS`) was **not distributed**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(snippet of the original rand_reduction_par.py)*\n",
    "~~~python\n",
    "if rank == 0:\n",
    "    COUNT = 10000000\n",
    "    SEED = COUNT    # for the time being, random seed is the same as COUNT\n",
    "\n",
    "    numpy.random.seed(SEED)\n",
    "    NUMBERS = numpy.random.random((COUNT,))\n",
    "else:\n",
    "    # Assign them with dummy values because the var names must exist on bcast below\n",
    "    COUNT = None\n",
    "    SEED = None\n",
    "    NUMBERS = None\n",
    "\n",
    "# Replicate the following data to all workers\n",
    "count_g = comm.bcast(COUNT, root=0)\n",
    "seed_g = comm.bcast(SEED, root=0)\n",
    "numbers_g = comm.bcast(NUMBERS, root=0)  ### This is problematic\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the starter's program, the random number was generated on the master rank, then *broadcast* to all the ranks.\n",
    "Consequently, each worker holds a full copy of `NUMBERS`, the primary data of the program.\n",
    "(There are even two copies of `NUMBERS` data in the master rank--verify that.\n",
    "This violates the principle of distributed-memory programming, where the working data should be distributed across the workers.\n",
    "Each worker should only hold the portion it needs perform its part of the computation.\n",
    "\n",
    "\n",
    "**EXERCISE**:\n",
    "Modify `rand_reduction_par.py` so that each worker receives only its relevant partition of the data.\n",
    "For example, worker rank 1 should only receive `NUMBERS[2500000:5000000]`.\n",
    "\n",
    "> **IMPORTANT**:\n",
    "> This exercise is central to the objective of our workshop, so be sure to attempt this one.\n",
    "> You will need to modify the program to perform the correct data distribution *and* make the workers work correctly with their portions of the data.\n",
    "> Please create a copy of the original program and modify the copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCUSSION QUESTIONS**:\n",
    "\n",
    "1. For a given piece of data (e.g. an array), when does it make sense to *distribute* the data, and when can we just *replicate* it?\n",
    "What are the advantages and disadvantages of each choice?\n",
    "\n",
    "2. After data distribution, can process 1 access portion of the array that is in process 2?\n",
    "\n",
    "3. Does distributing data have any effect on the application timing? Why, or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-Additional_ex\"></a>\n",
    "## 7. Additional Improvements\n",
    "\n",
    "Besides the critical data distribution, there are a number improvements that can be made in the starter's version of the parallel code.\n",
    "\n",
    "### 7.1 Using Scatter Operation\n",
    "\n",
    "**EXERCISE**:\n",
    "The distribution of work (`U` and `L`) was done using a series of `send`'s on the master side, and a single `recv` on the other workers.\n",
    "Of course, this is exactly what the `scatter` funtion does!\n",
    "Please replace the `send`/`recv` combination in `rand_reduction_par.py` with a single call of `scatter`.\n",
    "Applying this modification will reduce the number of MPI function calls in the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Problem Decomposition on Worker Processes\n",
    "\n",
    "The domain decomposition for a given rank is often a well-defined computation that can be carried out *independently* by each worker process.\n",
    "\n",
    "**QUESTIONS**:\n",
    "\n",
    "* On the original starter's parallel program, can we do the domain decomposition on the worker processes?\n",
    "\n",
    "* On the parallel program with properly distributed data, can we do the domain decomposition on the worker processes?\n",
    "\n",
    "* If this can be done, what are the adantages of performing the domain decomposition in parallel?\n",
    "  Applying this modification can potentially reduce the amount of data exchange at the start of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## MPI Improvement Challenges\n",
    ">\n",
    "> The following subsections contain more extensive programming exercises that may require significant reworking of the program.\n",
    "> These exercises are quite profitable to highlight common issues encountered in high-performance computing in the real world.\n",
    "> You are encouraged to attempt one or more of them on your own, and use our training's Slack channel to discuss your issues or findings.\n",
    "\n",
    "\n",
    "### 7.3 Conserving Memory Usage (Challenge)\n",
    "\n",
    "The original code generates *all* the random numbers in the master process before dispersing all of them to the worker processes.\n",
    "This is a problem when the data is extremely large.\n",
    "One way to get around this is to use *pipelining*, by generating chunks of random numbers and let those be processed first before generating the next batch.\n",
    "\n",
    "**EXERCISE**: Modify `rand_reduction_par.py` to take this approach.\n",
    "\n",
    "*Hint*: In this approach, the master process may have to take a unique role of providing the random numbers to all the workers, i.e. it does not participate in the computation as the rest of the workers.\n",
    "\n",
    "\n",
    "### 7.4 Speeding Up Random Number Generation (Challenge)\n",
    "\n",
    "The `numpy.random.random` function used in the reduction code generates the so-called *pseudo-random numbers*, i.e. a stream of numbers that look random in the eyes, but they are actually deterministically generated (i.e. can be replicated).\n",
    "The generation of pseudo-random numbers is a serious bottleneck in parallel computing.\n",
    "In real computing, we can use *parallel random number generator* to let workers generate their own stream of random numbers independently, therefore avoiding one process becoming the bottleneck to this process.\n",
    "However, this also leads to issues in reproducibility: The computed results cannot be reproduced unless we use exactly the same set of random number streams--which mostly translates to repeating the computation with exactly the same parallel configuration.\n",
    "In many computing applications, this is not a serious issue because the results from different computations have to only match statistically.\n",
    "\n",
    "**EXERCISE**: Modify `rand_reduction_par.py` to use parallel random number generators.\n",
    "\n",
    "> *Hints:* Start from numpy documentation: https://numpy.org/devdocs/reference/random/parallel.html .\n",
    "> On Wahab, you must use numpy version 1.17 to use `SeedSequence`.\n",
    "\n",
    "(As an alternative, find resources on parallel random number generators.)\n",
    "Hint: for many good random number generators such as that provided by `numpy`, we can pre-mix the MPI rank into the random seed, with optional computation of hash such as MD5 or SHA1 or SHA256 to ensure both random stream independence *and* reproducibility of the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The objective of this hands-on lesson module is to give you a \"taste\" of MPI's basic capabilities to enable parallel programming, and to guide you through a hands-on experience of parallelizing a simple program, (nearly) from scratch.\n",
    "\n",
    "Programming a parallel involves both science and art--even more so than writing a serial program.\n",
    "In creating a parallel program, there are lot of design decisions that has be made with much consideration, because each of these may dramatically improve or hurt performance.\n",
    "It takes some experience to judge whether to parallelize a portion of a code or not, and to decide the distribution layout of the data, and so on.\n",
    "These considerations are beyond the scope of this workshop.\n",
    "Please refer to some learning resources below to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Resources\n",
    "\n",
    "The following resources are valuable if you want to gain mastery in parallel programming using MPI.\n",
    "Most resources will use C/C++/Fortran languages because they are what defined in the standard.\n",
    "(Truthfully, if you aim for truly high performance, you should seriously consider programming in these languages.)\n",
    "\n",
    "### Message Passing Interface (MPI) -- A Tutorial by LLNL\n",
    "\n",
    "https://hpc-tutorials.llnl.gov/mpi/\n",
    "\n",
    "Written for C/C++/Fortran languages.\n",
    "Has more complete coverage than basic functionalities, to include derived data types and topology.\n",
    "\n",
    "\n",
    "### MPI Tutorial\n",
    "\n",
    "<https://mpitutorial.com/tutorials/>\n",
    "\n",
    "Targeting C++ language.\n",
    "This excellent tutorial focuses on in-depth, technical discussion on each MPI capability and how to use them properly.\n",
    "Sample programs are provided.\n",
    "\n",
    "\n",
    "### Parallel Programming Concepts and High-Performance Computing: Introduction\n",
    "\n",
    "<https://cvw.cac.cornell.edu/parallel/default>\n",
    "\n",
    "Has a lot of high-level concepts on architecting a parallel program,\n",
    "as well as consideration for achieving high performance.\n",
    "\n",
    "\n",
    "### HPC University Bi-Weekly Challenge\n",
    "\n",
    "* Challenges: <http://hpcuniversity.org/students/weeklyChallenge/>\n",
    "* Resources: <http://hpcuniversity.org/students/weeklyChallenge/resources/>\n",
    "\n",
    "Contains many hands-on  exercises for MPI and high-performance programmings.\n",
    "Sample/starting programs are available for download.\n",
    "Note: Not all challenges are related to MPI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
